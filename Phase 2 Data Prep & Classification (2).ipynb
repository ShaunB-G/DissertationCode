{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdbf77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95b4414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shaun\\anaconda3\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Using cached tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n",
      "Successfully installed tokenizers-0.19.1\n",
      "Requirement already satisfied: torch in c:\\users\\shaun\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Downloading torch-2.4.1-cp39-cp39-win_amd64.whl (199.3 MB)\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.2/199.3 MB 26.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 11.0/199.3 MB 28.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 17.0/199.3 MB 27.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 22.3/199.3 MB 26.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 27.0/199.3 MB 25.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 30.4/199.3 MB 24.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 34.1/199.3 MB 23.0 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 37.7/199.3 MB 22.4 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 41.9/199.3 MB 22.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 46.1/199.3 MB 21.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 49.5/199.3 MB 21.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 51.9/199.3 MB 20.4 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 53.7/199.3 MB 19.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 55.6/199.3 MB 18.6 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 57.7/199.3 MB 18.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 60.3/199.3 MB 17.8 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 63.4/199.3 MB 17.5 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 65.5/199.3 MB 17.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 67.9/199.3 MB 16.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 70.5/199.3 MB 16.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 72.6/199.3 MB 16.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 75.0/199.3 MB 16.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.3/199.3 MB 15.8 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 80.0/199.3 MB 15.7 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 83.1/199.3 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 85.7/199.3 MB 15.5 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 88.1/199.3 MB 15.3 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 90.4/199.3 MB 15.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 93.3/199.3 MB 15.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 95.9/199.3 MB 15.0 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 98.3/199.3 MB 14.9 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 100.7/199.3 MB 14.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 103.3/199.3 MB 14.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 106.4/199.3 MB 14.7 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 109.8/199.3 MB 14.7 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 113.2/199.3 MB 14.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.9/199.3 MB 14.8 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 120.6/199.3 MB 14.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 124.5/199.3 MB 15.0 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 128.5/199.3 MB 15.1 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.6/199.3 MB 15.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 134.2/199.3 MB 15.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.8/199.3 MB 15.0 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 140.0/199.3 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 142.6/199.3 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 145.0/199.3 MB 14.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.6/199.3 MB 14.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 150.7/199.3 MB 14.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.8/199.3 MB 14.6 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 155.5/199.3 MB 14.6 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.5/199.3 MB 14.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 159.6/199.3 MB 14.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.0/199.3 MB 14.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 164.6/199.3 MB 14.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.5/199.3 MB 14.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 170.7/199.3 MB 14.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 174.1/199.3 MB 14.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 176.7/199.3 MB 14.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.8/199.3 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 181.1/199.3 MB 14.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.2/199.3 MB 14.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 185.9/199.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 188.7/199.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 190.8/199.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.5/199.3 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.1/199.3 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.0/199.3 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.2/199.3 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 199.3/199.3 MB 13.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "Successfully installed torch-2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Shaun\\anaconda3\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\n",
      "torchvision 0.19.0 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\shaun\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (16.0.6)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.60.0)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.7)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.12.1-cp39-cp39-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.2/385.0 MB 22.9 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 9.7/385.0 MB 24.1 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 13.6/385.0 MB 22.5 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 17.8/385.0 MB 21.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 21.5/385.0 MB 20.6 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 24.1/385.0 MB 19.1 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 26.7/385.0 MB 18.2 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 29.4/385.0 MB 17.6 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 32.5/385.0 MB 17.2 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 35.7/385.0 MB 16.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 38.8/385.0 MB 16.7 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 41.4/385.0 MB 16.3 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 43.8/385.0 MB 16.0 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 46.9/385.0 MB 15.9 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 50.3/385.0 MB 15.9 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 54.0/385.0 MB 15.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 57.4/385.0 MB 16.0 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 60.8/385.0 MB 15.9 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 63.2/385.0 MB 15.7 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 65.8/385.0 MB 15.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 68.7/385.0 MB 15.5 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 71.3/385.0 MB 15.3 MB/s eta 0:00:21\n",
      "   ------- -------------------------------- 74.4/385.0 MB 15.2 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 77.6/385.0 MB 15.2 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 80.5/385.0 MB 15.1 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 83.4/385.0 MB 15.1 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 86.5/385.0 MB 15.1 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 89.7/385.0 MB 15.1 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 92.5/385.0 MB 15.0 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 95.7/385.0 MB 15.0 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 99.1/385.0 MB 15.0 MB/s eta 0:00:20\n",
      "   ---------- ---------------------------- 102.0/385.0 MB 15.0 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 104.9/385.0 MB 14.9 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 108.3/385.0 MB 15.0 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 111.9/385.0 MB 15.0 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 115.6/385.0 MB 15.1 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 119.8/385.0 MB 15.2 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 124.0/385.0 MB 15.3 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 128.5/385.0 MB 15.4 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 131.9/385.0 MB 15.5 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 134.7/385.0 MB 15.4 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 137.9/385.0 MB 15.4 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 141.6/385.0 MB 15.4 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 145.2/385.0 MB 15.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 148.4/385.0 MB 15.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 151.5/385.0 MB 15.4 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 154.1/385.0 MB 15.4 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 157.3/385.0 MB 15.3 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 160.7/385.0 MB 15.3 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 164.4/385.0 MB 15.4 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 168.0/385.0 MB 15.5 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 172.0/385.0 MB 15.5 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 175.4/385.0 MB 15.5 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 179.0/385.0 MB 15.6 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 183.0/385.0 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 186.9/385.0 MB 15.7 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 191.1/385.0 MB 15.7 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 195.0/385.0 MB 15.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 199.5/385.0 MB 15.9 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 204.2/385.0 MB 16.0 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 208.1/385.0 MB 16.0 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 210.2/385.0 MB 15.9 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 211.8/385.0 MB 15.8 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 215.0/385.0 MB 15.8 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 218.6/385.0 MB 15.8 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 221.8/385.0 MB 15.8 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 224.9/385.0 MB 15.7 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 228.1/385.0 MB 15.7 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 230.9/385.0 MB 15.7 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 234.1/385.0 MB 15.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 237.2/385.0 MB 15.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 239.9/385.0 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 242.2/385.0 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 244.1/385.0 MB 15.4 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 245.6/385.0 MB 15.4 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 248.3/385.0 MB 15.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 251.1/385.0 MB 15.3 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 254.3/385.0 MB 15.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 257.7/385.0 MB 15.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 261.6/385.0 MB 15.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 265.6/385.0 MB 15.3 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 269.5/385.0 MB 15.3 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 272.4/385.0 MB 15.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 275.0/385.0 MB 15.1 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 277.9/385.0 MB 15.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 281.0/385.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 283.6/385.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 286.5/385.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 289.9/385.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 292.8/385.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 295.7/385.0 MB 15.0 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 299.1/385.0 MB 15.0 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 302.5/385.0 MB 15.1 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 305.9/385.0 MB 15.1 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 309.1/385.0 MB 15.1 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 312.5/385.0 MB 15.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 316.1/385.0 MB 15.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 320.1/385.0 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 324.3/385.0 MB 15.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 328.2/385.0 MB 15.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 332.4/385.0 MB 15.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 336.1/385.0 MB 15.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 339.7/385.0 MB 15.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 344.2/385.0 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 348.1/385.0 MB 15.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 352.3/385.0 MB 15.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 356.5/385.0 MB 15.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 360.4/385.0 MB 15.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.3/385.0 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 366.7/385.0 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 370.1/385.0 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.3/385.0 MB 15.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  376.4/385.0 MB 15.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  379.1/385.0 MB 15.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.9/385.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 15.1 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 14.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 3.7/5.5 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 17.7 MB/s eta 0:00:00\n",
      "Downloading optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Installing collected packages: flatbuffers, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.15.0\n",
      "    Uninstalling tensorflow-intel-2.15.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "Successfully installed flatbuffers-24.3.25 h5py-3.11.0 keras-3.5.0 ml-dtypes-0.4.1 optree-0.12.1 tensorboard-2.17.1 tensorflow-2.17.0 tensorflow-intel-2.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Shaun\\anaconda3\\Lib\\site-packages\\~l_dtypes'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Shaun\\anaconda3\\Lib\\site-packages\\~ensorflow'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\users\\shaun\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.20.0-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tokenizers) (0.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3)\n",
      "Using cached tokenizers-0.20.0-cp39-none-win_amd64.whl (2.3 MB)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "Successfully installed tokenizers-0.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.44.2 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.20.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in c:\\users\\shaun\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shaun\\anaconda3\\lib\\site-packages (from requests->huggingface-hub) (3.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\shaun\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall transformers\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade tokenizers\n",
    "!pip install --upgrade huggingface-hub\n",
    "!pip install --upgrade sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bafa5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23= pd.read_csv('twitter_dataset_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79b945ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.805038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.873134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.879556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Tweet_ID                                               Text  \\\n",
       "0           0         1  party least receive say single prevent prevent...   \n",
       "1           1         2  hotel still congress may member staff medium d...   \n",
       "2           2         3  nice debate industry year film generation push...   \n",
       "3           3         4  laugh explain situation career occur serious f...   \n",
       "4           4         5  involve sense former often approach government...   \n",
       "\n",
       "   Retweets  Likes            Timestamp Sentiment     Score  \n",
       "0         2     25  2023-01-30 11:00:51   Neutral  0.805038  \n",
       "1        35     29  2023-01-02 22:45:58   Neutral  0.926011  \n",
       "2        51     25  2023-01-18 11:25:19  Positive  0.873134  \n",
       "3        37     18  2023-04-10 22:06:29   Neutral  0.833324  \n",
       "4        27     80  2023-01-24 07:12:21   Neutral  0.879556  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2af7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Set stop words to English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Add 'rt' to remove retweet indicator in dataset (noise)\n",
    "stop_words.add(\"rt\")\n",
    "stop_words.add(\"user\")\n",
    "\n",
    "# Remove HTML entities from tweets\n",
    "def remove_html(raw_tweet):\n",
    "    entity_regex = r\"&[^\\s;]+;\"\n",
    "    tweet = re.sub(entity_regex, \"\", raw_tweet)\n",
    "    return tweet\n",
    "\n",
    "# Change the usernames to 'user'\n",
    "def change_username(raw_tweet):\n",
    "    regex = r\"@([^\\s]+)\"\n",
    "    tweet = re.sub(regex, \"user\", raw_tweet)\n",
    "    return tweet\n",
    "\n",
    "# Remove URLs\n",
    "def remove_url(raw_tweet):\n",
    "    url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    tweet = re.sub(url_regex, '', raw_tweet)\n",
    "    return tweet\n",
    "\n",
    "# Remove noisy symbols\n",
    "def remove_symbols(raw_tweet):\n",
    "    tweet = re.sub(r'[\\\"#:?\\'@*!`,._()-]', '', raw_tweet)\n",
    "    return tweet\n",
    "\n",
    "# Spell checker\n",
    "def spellcheck(raw_tweet):\n",
    "    spell = Speller(lang='en')\n",
    "    tweet = spell(raw_tweet)\n",
    "    return tweet\n",
    "\n",
    "# Remove stopwords and lemmatize\n",
    "from nltk.corpus import wordnet\n",
    "def remove_stopwords_and_lemmatize(raw_tweet):\n",
    "    tweet = raw_tweet.lower()\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tweet = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    tweet= \" \".join(tweet) #use to return tweets to sentence\n",
    "    return tweet\n",
    "\n",
    "# Function to clean all tweets by utilizing the above functions\n",
    "def preprocess(data):\n",
    "    clean = []\n",
    "    for tweet in data:\n",
    "        tweet = change_username(tweet)\n",
    "        tweet = remove_html(tweet)\n",
    "        tweet = remove_url(tweet)\n",
    "        tweet = remove_symbols(tweet)\n",
    "        #tweet = spellcheck(tweet)\n",
    "        tweet = remove_stopwords_and_lemmatize(tweet)\n",
    "        clean.append(tweet)\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4128b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list(df23['Text'])\n",
    "# Run the preprocessing function\n",
    "clean_tweet = preprocess(tweet_list)\n",
    "df23['Text']= clean_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa9c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID                                               Text  Retweets  \\\n",
       "0         1  party least receive say single prevent prevent...         2   \n",
       "1         2  hotel still congress may member staff medium d...        35   \n",
       "2         3  nice debate industry year film generation push...        51   \n",
       "3         4  laugh explain situation career occur serious f...        37   \n",
       "4         5  involve sense former often approach government...        27   \n",
       "\n",
       "   Likes            Timestamp  \n",
       "0     25  2023-01-30 11:00:51  \n",
       "1     29  2023-01-02 22:45:58  \n",
       "2     25  2023-01-18 11:25:19  \n",
       "3     18  2023-04-10 22:06:29  \n",
       "4     80  2023-01-24 07:12:21  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32c02180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tweet sentiment model Using a pipeline\n",
    "from transformers import pipeline\n",
    "task='sentiment'\n",
    "SentimentClassifierTweet = pipeline(\"text-classification\", model=f\"cardiffnlp/twitter-roberta-base-{task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5fe70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.805038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.873134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.879556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>cell without report weight could father change...</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>2023-03-30 09:56:07</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.846128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>receive difference responsibility build let de...</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2023-01-02 03:15:54</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.756050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>five sort guy politics somebody pretty magazin...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-22 20:08:31</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.896401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>reveal table state view manager fly yeah daugh...</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-24 15:17:03</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.873683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>list allow family rather continue agency messa...</td>\n",
       "      <td>97</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-02-01 20:32:07</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.815786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID                                               Text  Retweets  \\\n",
       "0         1  party least receive say single prevent prevent...         2   \n",
       "1         2  hotel still congress may member staff medium d...        35   \n",
       "2         3  nice debate industry year film generation push...        51   \n",
       "3         4  laugh explain situation career occur serious f...        37   \n",
       "4         5  involve sense former often approach government...        27   \n",
       "5         6  cell without report weight could father change...        22   \n",
       "6         7  receive difference responsibility build let de...        12   \n",
       "7         8  five sort guy politics somebody pretty magazin...         0   \n",
       "8         9  reveal table state view manager fly yeah daugh...        15   \n",
       "9        10  list allow family rather continue agency messa...        97   \n",
       "\n",
       "   Likes            Timestamp Sentiment     Score  \n",
       "0     25  2023-01-30 11:00:51   LABEL_1  0.805038  \n",
       "1     29  2023-01-02 22:45:58   LABEL_1  0.926011  \n",
       "2     25  2023-01-18 11:25:19   LABEL_2  0.873134  \n",
       "3     18  2023-04-10 22:06:29   LABEL_1  0.833324  \n",
       "4     80  2023-01-24 07:12:21   LABEL_1  0.879556  \n",
       "5     75  2023-03-30 09:56:07   LABEL_1  0.846128  \n",
       "6     43  2023-01-02 03:15:54   LABEL_1  0.756050  \n",
       "7     12  2023-01-22 20:08:31   LABEL_1  0.896401  \n",
       "8     26  2023-03-24 15:17:03   LABEL_1  0.873683  \n",
       "9     28  2023-02-01 20:32:07   LABEL_1  0.815786  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a function to call for the whole dataframe\n",
    "def FunctionBERTSentimentTweet(inpText):\n",
    "    result = SentimentClassifierTweet(inpText)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# BERTTweet sentiment result function for every tweet\n",
    "df23[['Sentiment', 'Score']] = df23['Text'].apply(lambda x: pd.Series(FunctionBERTSentimentTweet(x)))\n",
    "\n",
    "# Displaying the first 10 rows\n",
    "df23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef645ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.805038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.873134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.879556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>cell without report weight could father change...</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>2023-03-30 09:56:07</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.846128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>receive difference responsibility build let de...</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2023-01-02 03:15:54</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.756050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>five sort guy politics somebody pretty magazin...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-22 20:08:31</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.896401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>reveal table state view manager fly yeah daugh...</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-24 15:17:03</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.873683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>list allow family rather continue agency messa...</td>\n",
       "      <td>97</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-02-01 20:32:07</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.815786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet_ID                                               Text  Retweets  \\\n",
       "0         1  party least receive say single prevent prevent...         2   \n",
       "1         2  hotel still congress may member staff medium d...        35   \n",
       "2         3  nice debate industry year film generation push...        51   \n",
       "3         4  laugh explain situation career occur serious f...        37   \n",
       "4         5  involve sense former often approach government...        27   \n",
       "5         6  cell without report weight could father change...        22   \n",
       "6         7  receive difference responsibility build let de...        12   \n",
       "7         8  five sort guy politics somebody pretty magazin...         0   \n",
       "8         9  reveal table state view manager fly yeah daugh...        15   \n",
       "9        10  list allow family rather continue agency messa...        97   \n",
       "\n",
       "   Likes            Timestamp Sentiment     Score  \n",
       "0     25  2023-01-30 11:00:51   Neutral  0.805038  \n",
       "1     29  2023-01-02 22:45:58   Neutral  0.926011  \n",
       "2     25  2023-01-18 11:25:19  Positive  0.873134  \n",
       "3     18  2023-04-10 22:06:29   Neutral  0.833324  \n",
       "4     80  2023-01-24 07:12:21   Neutral  0.879556  \n",
       "5     75  2023-03-30 09:56:07   Neutral  0.846128  \n",
       "6     43  2023-01-02 03:15:54   Neutral  0.756050  \n",
       "7     12  2023-01-22 20:08:31   Neutral  0.896401  \n",
       "8     26  2023-03-24 15:17:03   Neutral  0.873683  \n",
       "9     28  2023-02-01 20:32:07   Neutral  0.815786  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23['Sentiment'].replace('LABEL_0', 'Negative', inplace=True) #Negative\n",
    "df23['Sentiment'].replace('LABEL_1', 'Neutral', inplace=True) #Neutral\n",
    "df23['Sentiment'].replace('LABEL_2', 'Positive', inplace=True) #Positive\n",
    "# Displaying the first 10 rows\n",
    "df23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7526bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23.to_csv('twitter_dataset_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55dc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23= pd.read_csv('twitter_dataset_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee136be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Score', ylabel='Sentiment'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='Score', y='Sentiment', hue=None, data=df23, whis=1.5, notch=False, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddb80d",
   "metadata": {},
   "source": [
    "## Classification Twitter 2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a096851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.805038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.873134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.833324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.879556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Tweet_ID                                               Text  \\\n",
       "0           0         1  party least receive say single prevent prevent...   \n",
       "1           1         2  hotel still congress may member staff medium d...   \n",
       "2           2         3  nice debate industry year film generation push...   \n",
       "3           3         4  laugh explain situation career occur serious f...   \n",
       "4           4         5  involve sense former often approach government...   \n",
       "\n",
       "   Retweets  Likes            Timestamp Sentiment     Score  \n",
       "0         2     25  2023-01-30 11:00:51   Neutral  0.805038  \n",
       "1        35     29  2023-01-02 22:45:58   Neutral  0.926011  \n",
       "2        51     25  2023-01-18 11:25:19  Positive  0.873134  \n",
       "3        37     18  2023-04-10 22:06:29   Neutral  0.833324  \n",
       "4        27     80  2023-01-24 07:12:21   Neutral  0.879556  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23=pd.read_csv('twitter_dataset_2023.csv')\n",
    "df23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70be4e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.805038</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.926011</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.833324</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.879556</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>cell without report weight could father change...</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "      <td>2023-03-30 09:56:07</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.846128</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>receive difference responsibility build let de...</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2023-01-02 03:15:54</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.756050</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>five sort guy politics somebody pretty magazin...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-22 20:08:31</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.896401</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>reveal table state view manager fly yeah daugh...</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-03-24 15:17:03</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.873683</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>list allow family rather continue agency messa...</td>\n",
       "      <td>97</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-02-01 20:32:07</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.815786</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>image simply article list event imagine want r...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-01 08:31:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.852198</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>hold central seem miss look none u century met...</td>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>2023-02-07 13:22:19</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.740632</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>paper field audience read pick suddenly republ...</td>\n",
       "      <td>12</td>\n",
       "      <td>99</td>\n",
       "      <td>2023-03-15 07:21:43</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.875194</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>population way sport late strategy pay positiv...</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>2023-02-07 07:30:39</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.675873</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>red thousand low answer walk film follow able ...</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-16 04:15:11</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.838701</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>describe school building play believe finish h...</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>2023-05-11 14:06:03</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.676920</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>activity one western color agreement visit yes...</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "      <td>2023-05-11 14:01:17</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>color since door without crime increase three ...</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>2023-03-10 18:11:20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.846143</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>majority risk put conference new partner step ...</td>\n",
       "      <td>86</td>\n",
       "      <td>41</td>\n",
       "      <td>2023-01-07 06:22:28</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.884404</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>push chair store attention trade thing learn s...</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>2023-02-14 15:21:54</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.859839</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>stand man analysis remain culture friend produ...</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-03-18 02:46:51</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.690560</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>increase law owner main pick kid study white h...</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>2023-05-02 19:18:59</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.844726</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "      <td>thought meet participant value white whole hig...</td>\n",
       "      <td>63</td>\n",
       "      <td>78</td>\n",
       "      <td>2023-04-07 05:12:00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.660154</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>330</td>\n",
       "      <td>young night war understand team baby agent cla...</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-01-22 11:05:50</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.827656</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>408</td>\n",
       "      <td>thousand indeed majority thing reach attack go...</td>\n",
       "      <td>97</td>\n",
       "      <td>37</td>\n",
       "      <td>2023-03-03 11:31:10</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.658167</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>491</td>\n",
       "      <td>always election sort movie deal consider away ...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-08 02:40:40</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.819559</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>532</td>\n",
       "      <td>like amount cold check sit interest laugh stag...</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-03-07 15:52:41</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.736783</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>614</td>\n",
       "      <td>option trip investment organization scene eigh...</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "      <td>2023-02-05 02:37:14</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.843108</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "      <td>716</td>\n",
       "      <td>data le contain hard cultural half cost dog co...</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>2023-03-17 17:46:03</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.779441</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>742</td>\n",
       "      <td>742</td>\n",
       "      <td>743</td>\n",
       "      <td>pull white campaign management present job ima...</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>2023-03-02 20:50:01</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>805</td>\n",
       "      <td>number little type together describe often thi...</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-06 02:22:04</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.783073</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>817</td>\n",
       "      <td>817</td>\n",
       "      <td>818</td>\n",
       "      <td>man identify democrat space industry certain h...</td>\n",
       "      <td>25</td>\n",
       "      <td>77</td>\n",
       "      <td>2023-05-12 17:58:00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.819545</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>867</td>\n",
       "      <td>867</td>\n",
       "      <td>868</td>\n",
       "      <td>theory pressure watch take somebody everybody ...</td>\n",
       "      <td>64</td>\n",
       "      <td>82</td>\n",
       "      <td>2023-01-02 01:33:18</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.804366</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>959</td>\n",
       "      <td>soldier across nation store time cost white am...</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>2023-02-22 00:23:38</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.741481</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1121</td>\n",
       "      <td>1121</td>\n",
       "      <td>1122</td>\n",
       "      <td>executive offer ball employee ahead win police...</td>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>2023-03-25 23:05:22</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.815441</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1183</td>\n",
       "      <td>1183</td>\n",
       "      <td>1184</td>\n",
       "      <td>far guess education little author wall program...</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>2023-03-30 12:23:08</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.852149</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1194</td>\n",
       "      <td>1194</td>\n",
       "      <td>1195</td>\n",
       "      <td>rather drive something century clearly work ta...</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-01-10 22:17:33</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.884854</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1237</td>\n",
       "      <td>consider morning sense state whether white lik...</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-02-17 05:34:32</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.872126</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1462</td>\n",
       "      <td>1462</td>\n",
       "      <td>1463</td>\n",
       "      <td>step measure event tree truth white set countr...</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>2023-02-03 02:59:10</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.893064</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1513</td>\n",
       "      <td>1513</td>\n",
       "      <td>1514</td>\n",
       "      <td>special country factor outside news probably p...</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>2023-01-16 04:08:18</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.872559</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  Tweet_ID  \\\n",
       "0              0           0         1   \n",
       "1              1           1         2   \n",
       "2              2           2         3   \n",
       "3              3           3         4   \n",
       "4              4           4         5   \n",
       "5              5           5         6   \n",
       "6              6           6         7   \n",
       "7              7           7         8   \n",
       "8              8           8         9   \n",
       "9              9           9        10   \n",
       "10            10          10        11   \n",
       "11            11          11        12   \n",
       "12            12          12        13   \n",
       "13            13          13        14   \n",
       "14            14          14        15   \n",
       "15            15          15        16   \n",
       "16            16          16        17   \n",
       "17            17          17        18   \n",
       "18            18          18        19   \n",
       "19            19          19        20   \n",
       "20           180         180       181   \n",
       "21           192         192       193   \n",
       "22           289         289       290   \n",
       "23           329         329       330   \n",
       "24           407         407       408   \n",
       "25           490         490       491   \n",
       "26           531         531       532   \n",
       "27           613         613       614   \n",
       "28           715         715       716   \n",
       "29           742         742       743   \n",
       "30           804         804       805   \n",
       "31           817         817       818   \n",
       "32           867         867       868   \n",
       "33           958         958       959   \n",
       "34          1121        1121      1122   \n",
       "35          1183        1183      1184   \n",
       "36          1194        1194      1195   \n",
       "37          1236        1236      1237   \n",
       "38          1462        1462      1463   \n",
       "39          1513        1513      1514   \n",
       "\n",
       "                                                 Text  Retweets  Likes  \\\n",
       "0   party least receive say single prevent prevent...         2     25   \n",
       "1   hotel still congress may member staff medium d...        35     29   \n",
       "2   nice debate industry year film generation push...        51     25   \n",
       "3   laugh explain situation career occur serious f...        37     18   \n",
       "4   involve sense former often approach government...        27     80   \n",
       "5   cell without report weight could father change...        22     75   \n",
       "6   receive difference responsibility build let de...        12     43   \n",
       "7   five sort guy politics somebody pretty magazin...         0     12   \n",
       "8   reveal table state view manager fly yeah daugh...        15     26   \n",
       "9   list allow family rather continue agency messa...        97     28   \n",
       "10  image simply article list event imagine want r...        82      0   \n",
       "11  hold central seem miss look none u century met...        99     97   \n",
       "12  paper field audience read pick suddenly republ...        12     99   \n",
       "13  population way sport late strategy pay positiv...        20     47   \n",
       "14  red thousand low answer walk film follow able ...        27      4   \n",
       "15  describe school building play believe finish h...         3     99   \n",
       "16  activity one western color agreement visit yes...        43     89   \n",
       "17  color since door without crime increase three ...        55     38   \n",
       "18  majority risk put conference new partner step ...        86     41   \n",
       "19  push chair store attention trade thing learn s...        61     58   \n",
       "20  stand man analysis remain culture friend produ...        37     42   \n",
       "21  increase law owner main pick kid study white h...        39     81   \n",
       "22  thought meet participant value white whole hig...        63     78   \n",
       "23  young night war understand team baby agent cla...        40     16   \n",
       "24  thousand indeed majority thing reach attack go...        97     37   \n",
       "25  always election sort movie deal consider away ...        19      0   \n",
       "26  like amount cold check sit interest laugh stag...        44     24   \n",
       "27  option trip investment organization scene eigh...        75     27   \n",
       "28  data le contain hard cultural half cost dog co...        86     67   \n",
       "29  pull white campaign management present job ima...        49     50   \n",
       "30  number little type together describe often thi...        78      2   \n",
       "31  man identify democrat space industry certain h...        25     77   \n",
       "32  theory pressure watch take somebody everybody ...        64     82   \n",
       "33  soldier across nation store time cost white am...        27     49   \n",
       "34  executive offer ball employee ahead win police...        51     78   \n",
       "35  far guess education little author wall program...        92     75   \n",
       "36  rather drive something century clearly work ta...        24     19   \n",
       "37  consider morning sense state whether white lik...        78     29   \n",
       "38  step measure event tree truth white set countr...        66     71   \n",
       "39  special country factor outside news probably p...        45     90   \n",
       "\n",
       "              Timestamp Sentiment     Score  Classification  \\\n",
       "0   2023-01-30 11:00:51   Neutral  0.805038               2   \n",
       "1   2023-01-02 22:45:58   Neutral  0.926011               2   \n",
       "2   2023-01-18 11:25:19  Positive  0.873134               2   \n",
       "3   2023-04-10 22:06:29   Neutral  0.833324               2   \n",
       "4   2023-01-24 07:12:21   Neutral  0.879556               2   \n",
       "5   2023-03-30 09:56:07   Neutral  0.846128               2   \n",
       "6   2023-01-02 03:15:54   Neutral  0.756050               2   \n",
       "7   2023-01-22 20:08:31   Neutral  0.896401               2   \n",
       "8   2023-03-24 15:17:03   Neutral  0.873683               2   \n",
       "9   2023-02-01 20:32:07   Neutral  0.815786               2   \n",
       "10  2023-03-01 08:31:29   Neutral  0.852198               2   \n",
       "11  2023-02-07 13:22:19   Neutral  0.740632               2   \n",
       "12  2023-03-15 07:21:43   Neutral  0.875194               2   \n",
       "13  2023-02-07 07:30:39   Neutral  0.675873               2   \n",
       "14  2023-02-16 04:15:11   Neutral  0.838701               2   \n",
       "15  2023-05-11 14:06:03   Neutral  0.676920               2   \n",
       "16  2023-05-11 14:01:17   Neutral  0.855122               2   \n",
       "17  2023-03-10 18:11:20   Neutral  0.846143               2   \n",
       "18  2023-01-07 06:22:28   Neutral  0.884404               2   \n",
       "19  2023-02-14 15:21:54   Neutral  0.859839               2   \n",
       "20  2023-03-18 02:46:51  Positive  0.690560               0   \n",
       "21  2023-05-02 19:18:59   Neutral  0.844726               0   \n",
       "22  2023-04-07 05:12:00   Neutral  0.660154               0   \n",
       "23  2023-01-22 11:05:50   Neutral  0.827656               0   \n",
       "24  2023-03-03 11:31:10   Neutral  0.658167               0   \n",
       "25  2023-02-08 02:40:40   Neutral  0.819559               0   \n",
       "26  2023-03-07 15:52:41   Neutral  0.736783               0   \n",
       "27  2023-02-05 02:37:14   Neutral  0.843108               0   \n",
       "28  2023-03-17 17:46:03   Neutral  0.779441               0   \n",
       "29  2023-03-02 20:50:01   Neutral  0.751348               0   \n",
       "30  2023-01-06 02:22:04   Neutral  0.783073               0   \n",
       "31  2023-05-12 17:58:00   Neutral  0.819545               0   \n",
       "32  2023-01-02 01:33:18   Neutral  0.804366               0   \n",
       "33  2023-02-22 00:23:38   Neutral  0.741481               0   \n",
       "34  2023-03-25 23:05:22   Neutral  0.815441               0   \n",
       "35  2023-03-30 12:23:08   Neutral  0.852149               0   \n",
       "36  2023-01-10 22:17:33   Neutral  0.884854               0   \n",
       "37  2023-02-17 05:34:32   Neutral  0.872126               0   \n",
       "38  2023-02-03 02:59:10   Neutral  0.893064               0   \n",
       "39  2023-01-16 04:08:18   Neutral  0.872559               0   \n",
       "\n",
       "   Classification_Label  \n",
       "0               Neither  \n",
       "1               Neither  \n",
       "2               Neither  \n",
       "3               Neither  \n",
       "4               Neither  \n",
       "5               Neither  \n",
       "6               Neither  \n",
       "7               Neither  \n",
       "8               Neither  \n",
       "9               Neither  \n",
       "10              Neither  \n",
       "11              Neither  \n",
       "12              Neither  \n",
       "13              Neither  \n",
       "14              Neither  \n",
       "15              Neither  \n",
       "16              Neither  \n",
       "17              Neither  \n",
       "18              Neither  \n",
       "19              Neither  \n",
       "20                 Hate  \n",
       "21                 Hate  \n",
       "22                 Hate  \n",
       "23                 Hate  \n",
       "24                 Hate  \n",
       "25                 Hate  \n",
       "26                 Hate  \n",
       "27                 Hate  \n",
       "28                 Hate  \n",
       "29                 Hate  \n",
       "30                 Hate  \n",
       "31                 Hate  \n",
       "32                 Hate  \n",
       "33                 Hate  \n",
       "34                 Hate  \n",
       "35                 Hate  \n",
       "36                 Hate  \n",
       "37                 Hate  \n",
       "38                 Hate  \n",
       "39                 Hate  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column 'Variable'\n",
    "df23= pd.read_csv('classifiedtwitter_dataset_2023.csv')\n",
    "df2023 = df23.groupby('Classification_Label').head(20).reset_index(drop=True)\n",
    "df2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53006e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23.to_csv('classifiedtwitter_dataset_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e4727b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Define the path where the model and tokenizer were saved\n",
    "model_save_path = 'bert-base-uncased'\n",
    "\n",
    "# Load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained(model_save_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c88412df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Function to classify a single tweet\n",
    "def classify_tweet(tweet):\n",
    "    # Tokenize the tweet and convert to tensor\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Get model output (logits)\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted class (e.g., 0, 1, 2 for 'Hate', 'Offensive', 'Neither')\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a96207",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df23' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the classify_tweet function to each row of the 'Tweet' column and create a new column 'Classification'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df23[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf23\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(classify_tweet)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Map class IDs to labels (assuming 0: 'Hate', 1: 'Offensive', 2: 'Neither')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m class_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOffensive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeither\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df23' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply the classify_tweet function to each row of the 'Tweet' column and create a new column 'Classification'\n",
    "df23['Classification'] = df23['Text'].apply(classify_tweet)\n",
    "\n",
    "# Map class IDs to labels (assuming 0: 'Hate', 1: 'Offensive', 2: 'Neither')\n",
    "class_mapping = {0: 'Hate', 1: 'Offensive', 2: 'Neither'}\n",
    "df23['Classification_Label'] = df23['Classification'].map(class_mapping)\n",
    "\n",
    "# Print the DataFrame with new columns\n",
    "df23.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8558d7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neither    9871\n",
       "Hate        129\n",
       "Name: Classification_Label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23['Classification_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cee663d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>party least receive say single prevent prevent...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-30 11:00:51</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.805038</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>hotel still congress may member staff medium d...</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-01-02 22:45:58</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.926011</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>nice debate industry year film generation push...</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-01-18 11:25:19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>laugh explain situation career occur serious f...</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-04-10 22:06:29</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.833324</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>involve sense former often approach government...</td>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>2023-01-24 07:12:21</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.879556</td>\n",
       "      <td>2</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5028</td>\n",
       "      <td>5028</td>\n",
       "      <td>5029</td>\n",
       "      <td>experience thousand keep white third culture s...</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>2023-02-16 16:34:07</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.858212</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5152</td>\n",
       "      <td>5152</td>\n",
       "      <td>5153</td>\n",
       "      <td>stay actually civil ahead big finally heavy fe...</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>2023-05-12 19:59:35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.586107</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5253</td>\n",
       "      <td>5253</td>\n",
       "      <td>5254</td>\n",
       "      <td>base step price trouble turn boy alone movie g...</td>\n",
       "      <td>68</td>\n",
       "      <td>95</td>\n",
       "      <td>2023-03-12 22:14:26</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.703663</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>5284</td>\n",
       "      <td>5284</td>\n",
       "      <td>5285</td>\n",
       "      <td>newspaper need talk reduce share question thro...</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>2023-03-01 17:28:09</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.800509</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5512</td>\n",
       "      <td>5512</td>\n",
       "      <td>5513</td>\n",
       "      <td>kitchen among white offer author relationship ...</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>2023-05-06 09:15:42</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.595622</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0  Tweet_ID  \\\n",
       "0               0           0         1   \n",
       "1               1           1         2   \n",
       "2               2           2         3   \n",
       "3               3           3         4   \n",
       "4               4           4         5   \n",
       "..            ...         ...       ...   \n",
       "135          5028        5028      5029   \n",
       "136          5152        5152      5153   \n",
       "137          5253        5253      5254   \n",
       "138          5284        5284      5285   \n",
       "139          5512        5512      5513   \n",
       "\n",
       "                                                  Text  Retweets  Likes  \\\n",
       "0    party least receive say single prevent prevent...         2     25   \n",
       "1    hotel still congress may member staff medium d...        35     29   \n",
       "2    nice debate industry year film generation push...        51     25   \n",
       "3    laugh explain situation career occur serious f...        37     18   \n",
       "4    involve sense former often approach government...        27     80   \n",
       "..                                                 ...       ...    ...   \n",
       "135  experience thousand keep white third culture s...        66     94   \n",
       "136  stay actually civil ahead big finally heavy fe...        78     72   \n",
       "137  base step price trouble turn boy alone movie g...        68     95   \n",
       "138  newspaper need talk reduce share question thro...        38     40   \n",
       "139  kitchen among white offer author relationship ...        98     94   \n",
       "\n",
       "               Timestamp Sentiment     Score  Classification  \\\n",
       "0    2023-01-30 11:00:51   Neutral  0.805038               2   \n",
       "1    2023-01-02 22:45:58   Neutral  0.926011               2   \n",
       "2    2023-01-18 11:25:19  Positive  0.873134               2   \n",
       "3    2023-04-10 22:06:29   Neutral  0.833324               2   \n",
       "4    2023-01-24 07:12:21   Neutral  0.879556               2   \n",
       "..                   ...       ...       ...             ...   \n",
       "135  2023-02-16 16:34:07   Neutral  0.858212               0   \n",
       "136  2023-05-12 19:59:35  Positive  0.586107               0   \n",
       "137  2023-03-12 22:14:26   Neutral  0.703663               0   \n",
       "138  2023-03-01 17:28:09   Neutral  0.800509               0   \n",
       "139  2023-05-06 09:15:42  Positive  0.595622               0   \n",
       "\n",
       "    Classification_Label  \n",
       "0                Neither  \n",
       "1                Neither  \n",
       "2                Neither  \n",
       "3                Neither  \n",
       "4                Neither  \n",
       "..                   ...  \n",
       "135                 Hate  \n",
       "136                 Hate  \n",
       "137                 Hate  \n",
       "138                 Hate  \n",
       "139                 Hate  \n",
       "\n",
       "[140 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column 'Variable'\n",
    "df2023 = df23.groupby('Classification_Label').head(70).reset_index(drop=True)\n",
    "df2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2d15db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bf8c79eb9947a9bad1542cf43dc446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/348 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shaun\\.cache\\huggingface\\hub\\models--ctoraman--hate-speech-bert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b8478f45214868882ae1b6dc15335b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5f8ea70478453cb29989a3432b333b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660ba08e8a743bf973c8e0a842ebf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829488a125b419f9026fc62ba9558ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/881 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa72f3618fa415a9bf62fd024ecb0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "#https://huggingface.co/ctoraman/hate-speech-bert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ctoraman/hate-speech-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ctoraman/hate-speech-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model #Selected Sentiment Model!!!!!!!!!!!\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-large-hate-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-large-hate-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6353f51",
   "metadata": {},
   "source": [
    "## Class 2022 & 2023 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ff341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œTo believe that these social outcomes are a...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @DonaldJTrumpJr: When @realDonaldTrump firs...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  â€œTo believe that these social outcomes are a...   \n",
       "1  RT @DonaldJTrumpJr: When @realDonaldTrump firs...   \n",
       "\n",
       "                  CreateDate Keyword  \n",
       "0  2020-09-01 11:02:54+00:00  Asians  \n",
       "1  2020-03-03 17:04:39+00:00  Asians  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df= pd.read_csv('ClassData2022and2023.csv')\n",
    "Class22and23df= Class22and23df.drop(['TweetID','Username','Biased', 'Calling_Out', 'cohort'], axis=1)\n",
    "Class22and23df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c9287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list(Class22and23df['Text'].astype(str))\n",
    "# Run the preprocessing function\n",
    "clean_tweet = preprocess(tweet_list)\n",
    "Class22and23df['Text']= clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a41f977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  â€œto believe social outcome result systemic r...   \n",
       "1  first shut travel china dems said early xenoph...   \n",
       "\n",
       "                  CreateDate Keyword  \n",
       "0  2020-09-01 11:02:54+00:00  Asians  \n",
       "1  2020-03-03 17:04:39+00:00  Asians  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d2e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.532253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.485894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.953160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.494761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.949451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>got vote black latino jew asian pacific island...</td>\n",
       "      <td>2020-11-07 02:45:46+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.587284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>asian like japan colonized country weebs like ...</td>\n",
       "      <td>2020-05-24 20:51:32+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.638491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one interesting phenomenon romanization chines...</td>\n",
       "      <td>2020-11-28 08:55:31+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.733452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hate south asian alone appreciating culture hu...</td>\n",
       "      <td>2020-09-25 16:18:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.868050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trump insulted asian kung flu african american...</td>\n",
       "      <td>2020-06-24 15:48:01+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.876074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  â€œto believe social outcome result systemic r...   \n",
       "1  first shut travel china dems said early xenoph...   \n",
       "2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3  asian u least likely get coronavirus infection...   \n",
       "4  dumbest tweet ever read whole life racism thin...   \n",
       "5  got vote black latino jew asian pacific island...   \n",
       "6  asian like japan colonized country weebs like ...   \n",
       "7  one interesting phenomenon romanization chines...   \n",
       "8  hate south asian alone appreciating culture hu...   \n",
       "9  trump insulted asian kung flu african american...   \n",
       "\n",
       "                  CreateDate Keyword Sentiment     Score  \n",
       "0  2020-09-01 11:02:54+00:00  Asians   LABEL_0  0.532253  \n",
       "1  2020-03-03 17:04:39+00:00  Asians   LABEL_1  0.485894  \n",
       "2  2020-02-04 10:10:13+00:00  Asians   LABEL_2  0.953160  \n",
       "3  2020-05-19 01:14:11+00:00  Asians   LABEL_0  0.494761  \n",
       "4  2020-03-14 22:29:57+00:00  Asians   LABEL_0  0.949451  \n",
       "5  2020-11-07 02:45:46+00:00  Asians   LABEL_1  0.587284  \n",
       "6  2020-05-24 20:51:32+00:00  Asians   LABEL_0  0.638491  \n",
       "7  2020-11-28 08:55:31+00:00  Asians   LABEL_1  0.733452  \n",
       "8  2020-09-25 16:18:39+00:00  Asians   LABEL_0  0.868050  \n",
       "9  2020-06-24 15:48:01+00:00  Asians   LABEL_0  0.876074  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet sentiment model Using a pipeline\n",
    "from transformers import pipeline\n",
    "task='sentiment'\n",
    "SentimentClassifierTweet = pipeline(\"text-classification\", model=f\"cardiffnlp/twitter-roberta-base-{task}\")\n",
    "\n",
    "# Defining a function to call for the whole dataframe\n",
    "def FunctionBERTSentimentTweet(inpText):\n",
    "    result = SentimentClassifierTweet(inpText)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# BERTTweet sentiment result function for every tweet\n",
    "Class22and23df[['Sentiment', 'Score']] = Class22and23df['Text'].apply(lambda x: pd.Series(FunctionBERTSentimentTweet(x)))\n",
    "\n",
    "# Displaying the first 10 rows\n",
    "Class22and23df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a09d0010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.953160</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.494761</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>1</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  â€œto believe social outcome result systemic r...   \n",
       "1  first shut travel china dems said early xenoph...   \n",
       "2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3  asian u least likely get coronavirus infection...   \n",
       "4  dumbest tweet ever read whole life racism thin...   \n",
       "\n",
       "                  CreateDate Keyword Sentiment     Score  Classification  \\\n",
       "0  2020-09-01 11:02:54+00:00  Asians   LABEL_0  0.532253               0   \n",
       "1  2020-03-03 17:04:39+00:00  Asians   LABEL_1  0.485894               0   \n",
       "2  2020-02-04 10:10:13+00:00  Asians   LABEL_2  0.953160               0   \n",
       "3  2020-05-19 01:14:11+00:00  Asians   LABEL_0  0.494761               0   \n",
       "4  2020-03-14 22:29:57+00:00  Asians   LABEL_0  0.949451               1   \n",
       "\n",
       "  Classification_Label  \n",
       "0              Neither  \n",
       "1              Neither  \n",
       "2              Neither  \n",
       "3              Neither  \n",
       "4            Offensive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Define the path where the model and tokenizer were saved\n",
    "model_save_path = 'ctoraman/hate-speech-bert'\n",
    "\n",
    "# Load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained(model_save_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Function to classify a single tweet\n",
    "def classify_tweet(tweet):\n",
    "    # Tokenize the tweet and convert to tensor\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Get model output (logits)\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted class (e.g., 2, 1, 0 for 'Hate', 'Offensive', 'Neither')\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Apply the classify_tweet function to each row of the 'Tweet' column and create a new column 'Classification'\n",
    "Class22and23df['Classification'] = Class22and23df['Text'].apply(classify_tweet)\n",
    "\n",
    "# Map class IDs to labels \n",
    "class_mapping = {2: 'Hate', 1: 'Offensive', 0: 'Neither'}\n",
    "Class22and23df['Classification_Label'] = Class22and23df['Classification'].map(class_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b55b1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953160</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.494761</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>1</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0  â€œto believe social outcome result systemic r...   \n",
       "1           1  first shut travel china dems said early xenoph...   \n",
       "2           2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3           3  asian u least likely get coronavirus infection...   \n",
       "4           4  dumbest tweet ever read whole life racism thin...   \n",
       "\n",
       "                  CreateDate Keyword  Sentiment     Score  Classification  \\\n",
       "0  2020-09-01 11:02:54+00:00  Asians         -1  0.532253               0   \n",
       "1  2020-03-03 17:04:39+00:00  Asians          0  0.485894               0   \n",
       "2  2020-02-04 10:10:13+00:00  Asians          1  0.953160               0   \n",
       "3  2020-05-19 01:14:11+00:00  Asians         -1  0.494761               0   \n",
       "4  2020-03-14 22:29:57+00:00  Asians         -1  0.949451               1   \n",
       "\n",
       "  Classification_Label  Sentiment_Label  \n",
       "0              Neither               -1  \n",
       "1              Neither                0  \n",
       "2              Neither                1  \n",
       "3              Neither               -1  \n",
       "4            Offensive               -1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df['Sentiment_Label'].replace('LABEL_0', 'Negative', inplace=True) #Negative\n",
    "Class22and23df['Sentiment_Label'].replace('LABEL_1', 'Neutral', inplace=True) #Neutral\n",
    "Class22and23df['Sentiment_Label'].replace('LABEL_2', 'Positive', inplace=True) #Positive\n",
    "Class22and23df['Sentiment'].replace('LABEL_0', -1, inplace=True) #Negative\n",
    "Class22and23df['Sentiment'].replace('LABEL_1', 0, inplace=True) #Neutral\n",
    "Class22and23df['Sentiment_Label'].replace('LABEL_2', 1, inplace=True) #Positive\n",
    "Class22and23df['Sentiment']\n",
    "# Print the DataFrame with new columns\n",
    "Class22and23df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0613fe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neither      9777\n",
       "Offensive    1082\n",
       "Hate          273\n",
       "Name: Classification_Label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "Class22and23df['Classification_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6c4d6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    5861\n",
       "Neutral     4642\n",
       "Positive     629\n",
       "Name: Sentiment_Label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "Class22and23df['Sentiment_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca9812e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Class22and23df.to_csv('Classified22and23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4f5d9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_Num</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Month_Year_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2020</td>\n",
       "      <td>09</td>\n",
       "      <td>September</td>\n",
       "      <td>September 2020</td>\n",
       "      <td>2020-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2020</td>\n",
       "      <td>03</td>\n",
       "      <td>March</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953160</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2020</td>\n",
       "      <td>02</td>\n",
       "      <td>February</td>\n",
       "      <td>February 2020</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.494761</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2020</td>\n",
       "      <td>05</td>\n",
       "      <td>May</td>\n",
       "      <td>May 2020</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>1</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2020</td>\n",
       "      <td>03</td>\n",
       "      <td>March</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>11238</td>\n",
       "      <td>● muslim stayed back hindustan helped creating...</td>\n",
       "      <td>2022-10-16 18:31:51+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>2022-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>11239</td>\n",
       "      <td>noticed lot muslim online look see favourite g...</td>\n",
       "      <td>2022-05-15 07:13:29+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782608</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2022</td>\n",
       "      <td>05</td>\n",
       "      <td>May</td>\n",
       "      <td>May 2022</td>\n",
       "      <td>2022-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>11240</td>\n",
       "      <td>nothing good come remember muslim depend</td>\n",
       "      <td>2022-05-08 08:38:01+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.712164</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2022</td>\n",
       "      <td>05</td>\n",
       "      <td>May</td>\n",
       "      <td>May 2022</td>\n",
       "      <td>2022-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>11241</td>\n",
       "      <td>declared non clear plz dont say</td>\n",
       "      <td>2022-10-22 13:57:15+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550806</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>October 2022</td>\n",
       "      <td>2022-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>11242</td>\n",
       "      <td>bjp declared war poorest name encroachment ’ g...</td>\n",
       "      <td>2022-04-19 21:08:07+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2022</td>\n",
       "      <td>04</td>\n",
       "      <td>April</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11132 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               Text  \\\n",
       "0               0  â€œto believe social outcome result systemic r...   \n",
       "1               1  first shut travel china dems said early xenoph...   \n",
       "2               2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3               3  asian u least likely get coronavirus infection...   \n",
       "4               4  dumbest tweet ever read whole life racism thin...   \n",
       "...           ...                                                ...   \n",
       "11238       11238  ● muslim stayed back hindustan helped creating...   \n",
       "11239       11239  noticed lot muslim online look see favourite g...   \n",
       "11240       11240           nothing good come remember muslim depend   \n",
       "11241       11241                    declared non clear plz dont say   \n",
       "11242       11242  bjp declared war poorest name encroachment ’ g...   \n",
       "\n",
       "                      CreateDate  Keyword  Sentiment     Score  \\\n",
       "0      2020-09-01 11:02:54+00:00   Asians         -1  0.532253   \n",
       "1      2020-03-03 17:04:39+00:00   Asians          0  0.485894   \n",
       "2      2020-02-04 10:10:13+00:00   Asians          1  0.953160   \n",
       "3      2020-05-19 01:14:11+00:00   Asians         -1  0.494761   \n",
       "4      2020-03-14 22:29:57+00:00   Asians         -1  0.949451   \n",
       "...                          ...      ...        ...       ...   \n",
       "11238  2022-10-16 18:31:51+00:00  Muslims          0  0.689276   \n",
       "11239  2022-05-15 07:13:29+00:00  Muslims          1  0.782608   \n",
       "11240  2022-05-08 08:38:01+00:00  Muslims         -1  0.712164   \n",
       "11241  2022-10-22 13:57:15+00:00  Muslims          0  0.550806   \n",
       "11242  2022-04-19 21:08:07+00:00  Muslims         -1  0.725476   \n",
       "\n",
       "       Classification Classification_Label Sentiment_Label  Year Month_Num  \\\n",
       "0                   0              Neither        Negative  2020        09   \n",
       "1                   0              Neither         Neutral  2020        03   \n",
       "2                   0              Neither        Positive  2020        02   \n",
       "3                   0              Neither        Negative  2020        05   \n",
       "4                   1            Offensive        Negative  2020        03   \n",
       "...               ...                  ...             ...   ...       ...   \n",
       "11238               0              Neither         Neutral  2022        10   \n",
       "11239               0              Neither        Positive  2022        05   \n",
       "11240               0              Neither        Negative  2022        05   \n",
       "11241               0              Neither         Neutral  2022        10   \n",
       "11242               0              Neither        Negative  2022        04   \n",
       "\n",
       "           Month      Month_Year Month_Year_Date  \n",
       "0      September  September 2020      2020-09-01  \n",
       "1          March      March 2020      2020-03-01  \n",
       "2       February   February 2020      2020-02-01  \n",
       "3            May        May 2020      2020-05-01  \n",
       "4          March      March 2020      2020-03-01  \n",
       "...          ...             ...             ...  \n",
       "11238    October    October 2022      2022-10-01  \n",
       "11239        May        May 2022      2022-05-01  \n",
       "11240        May        May 2022      2022-05-01  \n",
       "11241    October    October 2022      2022-10-01  \n",
       "11242      April      April 2022      2022-04-01  \n",
       "\n",
       "[11132 rows x 14 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01d7c7",
   "metadata": {},
   "source": [
    "### Monthly 20 to 23 df data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd47a800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.953160</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.494761</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>1</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>11238</td>\n",
       "      <td>● muslim stayed back hindustan helped creating...</td>\n",
       "      <td>2022-10-16 18:31:51+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>11239</td>\n",
       "      <td>noticed lot muslim online look see favourite g...</td>\n",
       "      <td>2022-05-15 07:13:29+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.782608</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>11240</td>\n",
       "      <td>nothing good come remember muslim depend</td>\n",
       "      <td>2022-05-08 08:38:01+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.712164</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>11241</td>\n",
       "      <td>declared non clear plz dont say</td>\n",
       "      <td>2022-10-22 13:57:15+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.550806</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>11242</td>\n",
       "      <td>bjp declared war poorest name encroachment ’ g...</td>\n",
       "      <td>2022-04-19 21:08:07+00:00</td>\n",
       "      <td>Muslims</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.725476</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11243 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               Text  \\\n",
       "0               0  â€œto believe social outcome result systemic r...   \n",
       "1               1  first shut travel china dems said early xenoph...   \n",
       "2               2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3               3  asian u least likely get coronavirus infection...   \n",
       "4               4  dumbest tweet ever read whole life racism thin...   \n",
       "...           ...                                                ...   \n",
       "11238       11238  ● muslim stayed back hindustan helped creating...   \n",
       "11239       11239  noticed lot muslim online look see favourite g...   \n",
       "11240       11240           nothing good come remember muslim depend   \n",
       "11241       11241                    declared non clear plz dont say   \n",
       "11242       11242  bjp declared war poorest name encroachment ’ g...   \n",
       "\n",
       "                      CreateDate  Keyword Sentiment     Score  Classification  \\\n",
       "0      2020-09-01 11:02:54+00:00   Asians  Negative  0.532253               0   \n",
       "1      2020-03-03 17:04:39+00:00   Asians   Neutral  0.485894               0   \n",
       "2      2020-02-04 10:10:13+00:00   Asians  Positive  0.953160               0   \n",
       "3      2020-05-19 01:14:11+00:00   Asians  Negative  0.494761               0   \n",
       "4      2020-03-14 22:29:57+00:00   Asians  Negative  0.949451               1   \n",
       "...                          ...      ...       ...       ...             ...   \n",
       "11238  2022-10-16 18:31:51+00:00  Muslims   Neutral  0.689276               0   \n",
       "11239  2022-05-15 07:13:29+00:00  Muslims  Positive  0.782608               0   \n",
       "11240  2022-05-08 08:38:01+00:00  Muslims  Negative  0.712164               0   \n",
       "11241  2022-10-22 13:57:15+00:00  Muslims   Neutral  0.550806               0   \n",
       "11242  2022-04-19 21:08:07+00:00  Muslims  Negative  0.725476               0   \n",
       "\n",
       "      Classification_Label  \n",
       "0                  Neither  \n",
       "1                  Neither  \n",
       "2                  Neither  \n",
       "3                  Neither  \n",
       "4                Offensive  \n",
       "...                    ...  \n",
       "11238              Neither  \n",
       "11239              Neither  \n",
       "11240              Neither  \n",
       "11241              Neither  \n",
       "11242              Neither  \n",
       "\n",
       "[11243 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df =pd.read_csv('Classified22and23.csv')\n",
    "Class22and23df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda320e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â€œto believe social outcome result systemic r...</td>\n",
       "      <td>2020-09-01 11:02:54+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.532253</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first shut travel china dems said early xenoph...</td>\n",
       "      <td>2020-03-03 17:04:39+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485894</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...</td>\n",
       "      <td>2020-02-04 10:10:13+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953160</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>asian u least likely get coronavirus infection...</td>\n",
       "      <td>2020-05-19 01:14:11+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.494761</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dumbest tweet ever read whole life racism thin...</td>\n",
       "      <td>2020-03-14 22:29:57+00:00</td>\n",
       "      <td>Asians</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>1</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0  â€œto believe social outcome result systemic r...   \n",
       "1           1  first shut travel china dems said early xenoph...   \n",
       "2           2  goodmorning nice dayâ¤ï¸ followðÿ ‘ ‡ðÿ ‘ ‡ð...   \n",
       "3           3  asian u least likely get coronavirus infection...   \n",
       "4           4  dumbest tweet ever read whole life racism thin...   \n",
       "\n",
       "                  CreateDate Keyword  Sentiment     Score  Classification  \\\n",
       "0  2020-09-01 11:02:54+00:00  Asians         -1  0.532253               0   \n",
       "1  2020-03-03 17:04:39+00:00  Asians          0  0.485894               0   \n",
       "2  2020-02-04 10:10:13+00:00  Asians          1  0.953160               0   \n",
       "3  2020-05-19 01:14:11+00:00  Asians         -1  0.494761               0   \n",
       "4  2020-03-14 22:29:57+00:00  Asians         -1  0.949451               1   \n",
       "\n",
       "  Classification_Label Sentiment_Label  \n",
       "0              Neither        Negative  \n",
       "1              Neither         Neutral  \n",
       "2              Neither        Positive  \n",
       "3              Neither        Negative  \n",
       "4            Offensive        Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class22and23df['Sentiment_Label'] = Class22and23df['Sentiment']#.replace('LABEL_0', 'Negative', inplace=True) #Negative\n",
    "Class22and23df['Sentiment_Label'] = Class22and23df['Sentiment']#.replace('LABEL_1', 'Neutral', inplace=True) #Neutral\n",
    "Class22and23df['Sentiment_Label'] = Class22and23df['Sentiment']#.replace('LABEL_2', 'Positive', inplace=True) #Positive\n",
    "Class22and23df['Sentiment'].replace('Negative', -1, inplace=True) #Negative\n",
    "Class22and23df['Sentiment'].replace('Neutral', 0, inplace=True) #Neutral\n",
    "Class22and23df['Sentiment'].replace('Positive', 1, inplace=True) #Positive\n",
    "Class22and23df['Sentiment']\n",
    "# Print the DataFrame with new columns\n",
    "Class22and23df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ca9fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          CreateDate\n",
      "8427  Wed Sep 01 09:10:05 -0400 2021\n",
      "8428  Wed Sep 01 18:12:08 -0400 2021\n",
      "8429  Wed Sep 01 21:50:33 -0400 2021\n",
      "8430  Fri Sep 03 23:00:43 -0400 2021\n",
      "8431  Sat Sep 04 15:01:13 -0400 2021\n",
      "...                              ...\n",
      "8533  Tue Dec 21 14:41:45 -0500 2021\n",
      "8534  Fri Dec 24 11:24:53 -0500 2021\n",
      "8535  Mon Dec 27 11:49:39 -0500 2021\n",
      "8536  Mon Dec 27 16:48:48 -0500 2021\n",
      "8537  Fri Dec 31 11:11:21 -0500 2021\n",
      "\n",
      "[111 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for invalid date formats\n",
    "invalid_dates = Class22and23df[~Class22and23df['CreateDate'].str.contains(r'^\\d{4}-\\d{2}-\\d{2}')]\n",
    "\n",
    "# Display the invalid dates\n",
    "print(invalid_dates[['CreateDate']])\n",
    "\n",
    "# Drop rows where CreateDate doesn't match the expected pattern (YYYY-MM-DD)\n",
    "Class22and23df = Class22and23df[Class22and23df['CreateDate'].str.contains(r'^\\d{4}-\\d{2}-\\d{2}')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080163a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_14920\\2939282112.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Year'] = Class22and23df['CreateDate'].str[:4]  # Extract year (first 4 characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_14920\\2939282112.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Num'] = Class22and23df['CreateDate'].str[5:7]  # Extract month number (5th to 7th characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_14920\\2939282112.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month'] = Class22and23df['Month_Num'].map(month_mapping)  # Map month number to month name\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_14920\\2939282112.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Year'] = Class22and23df['Month'] + ' ' + Class22and23df['Year']\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_14920\\2939282112.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Year_Date'] = pd.to_datetime(Class22and23df['Year'] + '-' + Class22and23df['Month_Num'], format='%Y-%m')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neither_Tweets</th>\n",
       "      <th>Offensive_Tweets</th>\n",
       "      <th>Hate_Tweets</th>\n",
       "      <th>Total_Tweets</th>\n",
       "      <th>Hate_Tweet_Percentage</th>\n",
       "      <th>Offensive_Tweet_Percentage</th>\n",
       "      <th>Avg_Hate_Tweet_Score</th>\n",
       "      <th>Negative_Tweets</th>\n",
       "      <th>Neutral_Tweets</th>\n",
       "      <th>Positive_Tweets</th>\n",
       "      <th>Average_Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>January 2020</th>\n",
       "      <td>149</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>10.919540</td>\n",
       "      <td>0.839585</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.459770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2020</th>\n",
       "      <td>168</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>204</td>\n",
       "      <td>3.921569</td>\n",
       "      <td>13.725490</td>\n",
       "      <td>0.894565</td>\n",
       "      <td>118</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.519608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2020</th>\n",
       "      <td>168</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>206</td>\n",
       "      <td>1.941748</td>\n",
       "      <td>16.504854</td>\n",
       "      <td>0.824677</td>\n",
       "      <td>132</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2020</th>\n",
       "      <td>216</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>245</td>\n",
       "      <td>3.673469</td>\n",
       "      <td>8.163265</td>\n",
       "      <td>0.826559</td>\n",
       "      <td>139</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.518367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2020</th>\n",
       "      <td>161</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>18.137255</td>\n",
       "      <td>0.902638</td>\n",
       "      <td>103</td>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.446078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2020</th>\n",
       "      <td>406</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>544</td>\n",
       "      <td>10.477941</td>\n",
       "      <td>14.889706</td>\n",
       "      <td>0.822937</td>\n",
       "      <td>358</td>\n",
       "      <td>169</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.626838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2020</th>\n",
       "      <td>247</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>1.413428</td>\n",
       "      <td>11.307420</td>\n",
       "      <td>0.833781</td>\n",
       "      <td>175</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2020</th>\n",
       "      <td>251</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>287</td>\n",
       "      <td>1.393728</td>\n",
       "      <td>11.149826</td>\n",
       "      <td>0.845025</td>\n",
       "      <td>163</td>\n",
       "      <td>111</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.522648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2020</th>\n",
       "      <td>242</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>1.127820</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>0.874752</td>\n",
       "      <td>151</td>\n",
       "      <td>102</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2020</th>\n",
       "      <td>175</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>1.507538</td>\n",
       "      <td>10.552764</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>99</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.427136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2020</th>\n",
       "      <td>192</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>10.648148</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.449074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2020</th>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>1.834862</td>\n",
       "      <td>7.339450</td>\n",
       "      <td>0.925671</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.284404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January 2021</th>\n",
       "      <td>368</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>11.904762</td>\n",
       "      <td>0.921291</td>\n",
       "      <td>223</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2021</th>\n",
       "      <td>401</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>0.845346</td>\n",
       "      <td>277</td>\n",
       "      <td>157</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.545652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2021</th>\n",
       "      <td>688</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>808</td>\n",
       "      <td>2.351485</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.881083</td>\n",
       "      <td>528</td>\n",
       "      <td>248</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.613861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2021</th>\n",
       "      <td>363</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>423</td>\n",
       "      <td>2.836879</td>\n",
       "      <td>11.347518</td>\n",
       "      <td>0.827363</td>\n",
       "      <td>253</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.572104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2021</th>\n",
       "      <td>519</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>588</td>\n",
       "      <td>4.421769</td>\n",
       "      <td>7.312925</td>\n",
       "      <td>0.863117</td>\n",
       "      <td>346</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.542517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2021</th>\n",
       "      <td>390</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>437</td>\n",
       "      <td>0.686499</td>\n",
       "      <td>10.068650</td>\n",
       "      <td>0.855056</td>\n",
       "      <td>210</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.427918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2021</th>\n",
       "      <td>341</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>381</td>\n",
       "      <td>1.049869</td>\n",
       "      <td>9.448819</td>\n",
       "      <td>0.677867</td>\n",
       "      <td>198</td>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.467192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2021</th>\n",
       "      <td>310</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>345</td>\n",
       "      <td>3.188406</td>\n",
       "      <td>6.956522</td>\n",
       "      <td>0.785553</td>\n",
       "      <td>155</td>\n",
       "      <td>171</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.394203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2021</th>\n",
       "      <td>415</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>441</td>\n",
       "      <td>1.133787</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>0.857458</td>\n",
       "      <td>152</td>\n",
       "      <td>226</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.201814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2021</th>\n",
       "      <td>309</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>330</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>0.817054</td>\n",
       "      <td>127</td>\n",
       "      <td>178</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2021</th>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>408</td>\n",
       "      <td>2.205882</td>\n",
       "      <td>5.392157</td>\n",
       "      <td>0.793689</td>\n",
       "      <td>173</td>\n",
       "      <td>206</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2021</th>\n",
       "      <td>370</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>409</td>\n",
       "      <td>3.422983</td>\n",
       "      <td>6.112469</td>\n",
       "      <td>0.851450</td>\n",
       "      <td>174</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.352078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January 2022</th>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>2.074689</td>\n",
       "      <td>9.543568</td>\n",
       "      <td>0.845414</td>\n",
       "      <td>141</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.560166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2022</th>\n",
       "      <td>169</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>9.042553</td>\n",
       "      <td>0.594374</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.484043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2022</th>\n",
       "      <td>194</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>2.336449</td>\n",
       "      <td>7.009346</td>\n",
       "      <td>0.835450</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.364486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2022</th>\n",
       "      <td>206</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>220</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>0.775288</td>\n",
       "      <td>112</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.427273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2022</th>\n",
       "      <td>216</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "      <td>1.255230</td>\n",
       "      <td>8.368201</td>\n",
       "      <td>0.854348</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.355649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2022</th>\n",
       "      <td>157</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.770115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.494253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2022</th>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>0.950897</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.420455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2022</th>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>182</td>\n",
       "      <td>5.494505</td>\n",
       "      <td>4.945055</td>\n",
       "      <td>0.786383</td>\n",
       "      <td>92</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.456044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2022</th>\n",
       "      <td>248</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>271</td>\n",
       "      <td>0.738007</td>\n",
       "      <td>7.749077</td>\n",
       "      <td>0.907944</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.369004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2022</th>\n",
       "      <td>290</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>337</td>\n",
       "      <td>1.483680</td>\n",
       "      <td>12.462908</td>\n",
       "      <td>0.809552</td>\n",
       "      <td>168</td>\n",
       "      <td>152</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.448071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2022</th>\n",
       "      <td>260</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>287</td>\n",
       "      <td>2.090592</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>0.811315</td>\n",
       "      <td>152</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.470383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2022</th>\n",
       "      <td>185</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>0.916829</td>\n",
       "      <td>96</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.402778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Neither_Tweets  Offensive_Tweets  Hate_Tweets  Total_Tweets  \\\n",
       "Month_Year                                                                    \n",
       "January 2020               149                19            6           174   \n",
       "February 2020              168                28            8           204   \n",
       "March 2020                 168                34            4           206   \n",
       "April 2020                 216                20            9           245   \n",
       "May 2020                   161                37            6           204   \n",
       "June 2020                  406                81           57           544   \n",
       "July 2020                  247                32            4           283   \n",
       "August 2020                251                32            4           287   \n",
       "September 2020             242                21            3           266   \n",
       "October 2020               175                21            3           199   \n",
       "November 2020              192                23            1           216   \n",
       "December 2020               99                 8            2           109   \n",
       "January 2021               368                50            2           420   \n",
       "February 2021              401                54            5           460   \n",
       "March 2021                 688               101           19           808   \n",
       "April 2021                 363                48           12           423   \n",
       "May 2021                   519                43           26           588   \n",
       "June 2021                  390                44            3           437   \n",
       "July 2021                  341                36            4           381   \n",
       "August 2021                310                24           11           345   \n",
       "September 2021             415                21            5           441   \n",
       "October 2021               309                12            9           330   \n",
       "November 2021              377                22            9           408   \n",
       "December 2021              370                25           14           409   \n",
       "January 2022               213                23            5           241   \n",
       "February 2022              169                17            2           188   \n",
       "March 2022                 194                15            5           214   \n",
       "April 2022                 206                 7            7           220   \n",
       "May 2022                   216                20            3           239   \n",
       "June 2022                  157                17            0           174   \n",
       "July 2022                  151                24            1           176   \n",
       "August 2022                163                 9           10           182   \n",
       "September 2022             248                21            2           271   \n",
       "October 2022               290                42            5           337   \n",
       "November 2022              260                21            6           287   \n",
       "December 2022              185                30            1           216   \n",
       "\n",
       "                Hate_Tweet_Percentage  Offensive_Tweet_Percentage  \\\n",
       "Month_Year                                                          \n",
       "January 2020                 3.448276                   10.919540   \n",
       "February 2020                3.921569                   13.725490   \n",
       "March 2020                   1.941748                   16.504854   \n",
       "April 2020                   3.673469                    8.163265   \n",
       "May 2020                     2.941176                   18.137255   \n",
       "June 2020                   10.477941                   14.889706   \n",
       "July 2020                    1.413428                   11.307420   \n",
       "August 2020                  1.393728                   11.149826   \n",
       "September 2020               1.127820                    7.894737   \n",
       "October 2020                 1.507538                   10.552764   \n",
       "November 2020                0.462963                   10.648148   \n",
       "December 2020                1.834862                    7.339450   \n",
       "January 2021                 0.476190                   11.904762   \n",
       "February 2021                1.086957                   11.739130   \n",
       "March 2021                   2.351485                   12.500000   \n",
       "April 2021                   2.836879                   11.347518   \n",
       "May 2021                     4.421769                    7.312925   \n",
       "June 2021                    0.686499                   10.068650   \n",
       "July 2021                    1.049869                    9.448819   \n",
       "August 2021                  3.188406                    6.956522   \n",
       "September 2021               1.133787                    4.761905   \n",
       "October 2021                 2.727273                    3.636364   \n",
       "November 2021                2.205882                    5.392157   \n",
       "December 2021                3.422983                    6.112469   \n",
       "January 2022                 2.074689                    9.543568   \n",
       "February 2022                1.063830                    9.042553   \n",
       "March 2022                   2.336449                    7.009346   \n",
       "April 2022                   3.181818                    3.181818   \n",
       "May 2022                     1.255230                    8.368201   \n",
       "June 2022                    0.000000                    9.770115   \n",
       "July 2022                    0.568182                   13.636364   \n",
       "August 2022                  5.494505                    4.945055   \n",
       "September 2022               0.738007                    7.749077   \n",
       "October 2022                 1.483680                   12.462908   \n",
       "November 2022                2.090592                    7.317073   \n",
       "December 2022                0.462963                   13.888889   \n",
       "\n",
       "                Avg_Hate_Tweet_Score  Negative_Tweets  Neutral_Tweets  \\\n",
       "Month_Year                                                              \n",
       "January 2020                0.839585               92              70   \n",
       "February 2020               0.894565              118              74   \n",
       "March 2020                  0.824677              132              68   \n",
       "April 2020                  0.826559              139              94   \n",
       "May 2020                    0.902638              103              89   \n",
       "June 2020                   0.822937              358             169   \n",
       "July 2020                   0.833781              175              96   \n",
       "August 2020                 0.845025              163             111   \n",
       "September 2020              0.874752              151             102   \n",
       "October 2020                0.871452               99              86   \n",
       "November 2020               0.880459              109              95   \n",
       "December 2020               0.925671               41              58   \n",
       "January 2021                0.921291              223             184   \n",
       "February 2021               0.845346              277             157   \n",
       "March 2021                  0.881083              528             248   \n",
       "April 2021                  0.827363              253             159   \n",
       "May 2021                    0.863117              346             215   \n",
       "June 2021                   0.855056              210             204   \n",
       "July 2021                   0.677867              198             163   \n",
       "August 2021                 0.785553              155             171   \n",
       "September 2021              0.857458              152             226   \n",
       "October 2021                0.817054              127             178   \n",
       "November 2021               0.793689              173             206   \n",
       "December 2021               0.851450              174             205   \n",
       "January 2022                0.845414              141              94   \n",
       "February 2022               0.594374               95              89   \n",
       "March 2022                  0.835450               95             102   \n",
       "April 2022                  0.775288              112              90   \n",
       "May 2022                    0.854348              107             110   \n",
       "June 2022                        NaN               97              66   \n",
       "July 2022                   0.950897               84              82   \n",
       "August 2022                 0.786383               92              81   \n",
       "September 2022              0.907944              126             119   \n",
       "October 2022                0.809552              168             152   \n",
       "November 2022               0.811315              152             118   \n",
       "December 2022               0.916829               96             111   \n",
       "\n",
       "                Positive_Tweets  Average_Sentiment  \n",
       "Month_Year                                          \n",
       "January 2020                 12          -0.459770  \n",
       "February 2020                12          -0.519608  \n",
       "March 2020                    6          -0.611650  \n",
       "April 2020                   12          -0.518367  \n",
       "May 2020                     12          -0.446078  \n",
       "June 2020                    17          -0.626838  \n",
       "July 2020                    12          -0.575972  \n",
       "August 2020                  13          -0.522648  \n",
       "September 2020               13          -0.518797  \n",
       "October 2020                 14          -0.427136  \n",
       "November 2020                12          -0.449074  \n",
       "December 2020                10          -0.284404  \n",
       "January 2021                 13          -0.500000  \n",
       "February 2021                26          -0.545652  \n",
       "March 2021                   32          -0.613861  \n",
       "April 2021                   11          -0.572104  \n",
       "May 2021                     27          -0.542517  \n",
       "June 2021                    23          -0.427918  \n",
       "July 2021                    20          -0.467192  \n",
       "August 2021                  19          -0.394203  \n",
       "September 2021               63          -0.201814  \n",
       "October 2021                 25          -0.309091  \n",
       "November 2021                29          -0.352941  \n",
       "December 2021                30          -0.352078  \n",
       "January 2022                  6          -0.560166  \n",
       "February 2022                 4          -0.484043  \n",
       "March 2022                   17          -0.364486  \n",
       "April 2022                   18          -0.427273  \n",
       "May 2022                     22          -0.355649  \n",
       "June 2022                    11          -0.494253  \n",
       "July 2022                    10          -0.420455  \n",
       "August 2022                   9          -0.456044  \n",
       "September 2022               26          -0.369004  \n",
       "October 2022                 17          -0.448071  \n",
       "November 2022                17          -0.470383  \n",
       "December 2022                 9          -0.402778  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a mapping of month numbers to names\n",
    "month_mapping = {\n",
    "    '01': 'January', '02': 'February', '03': 'March', '04': 'April',\n",
    "    '05': 'May', '06': 'June', '07': 'July', '08': 'August',\n",
    "    '09': 'September', '10': 'October', '11': 'November', '12': 'December'\n",
    "}\n",
    "\n",
    "# Extract the year and month as strings\n",
    "Class22and23df['Year'] = Class22and23df['CreateDate'].str[:4]  # Extract year (first 4 characters)\n",
    "Class22and23df['Month_Num'] = Class22and23df['CreateDate'].str[5:7]  # Extract month number (5th to 7th characters)\n",
    "Class22and23df['Month'] = Class22and23df['Month_Num'].map(month_mapping)  # Map month number to month name\n",
    "\n",
    "# Combine year and month into one column\n",
    "Class22and23df['Month_Year'] = Class22and23df['Month'] + ' ' + Class22and23df['Year']\n",
    "\n",
    "# Convert 'Month_Year' to a datetime object for proper sorting\n",
    "Class22and23df['Month_Year_Date'] = pd.to_datetime(Class22and23df['Year'] + '-' + Class22and23df['Month_Num'], format='%Y-%m')\n",
    "\n",
    "# Create a pivot table to split the 'Classification' values\n",
    "# Count tweets for each classification (0=Neither, 1=Offensive, 2=Hate) per month\n",
    "monthly_classifications = Class22and23df.pivot_table(index=['Month_Year', 'Month_Year_Date'],\n",
    "                                                     columns='Classification',\n",
    "                                                     aggfunc='size',\n",
    "                                                     fill_value=0).reset_index()\n",
    "\n",
    "# Rename the columns for better readability\n",
    "monthly_classifications = monthly_classifications.rename(columns={0: 'Neither_Tweets', 1: 'Offensive_Tweets', 2: 'Hate_Tweets'})\n",
    "\n",
    "# Sort the data by 'Month_Year_Date' to ensure proper date order\n",
    "monthly_classifications = monthly_classifications.sort_values(by='Month_Year_Date').drop(columns='Month_Year_Date')\n",
    "\n",
    "# Add a new column 'Total_Tweets' for the total count of tweets per month\n",
    "monthly_classifications['Total_Tweets'] = monthly_classifications[['Neither_Tweets', 'Offensive_Tweets', 'Hate_Tweets']].sum(axis=1)\n",
    "\n",
    "# Calculate the percentage of hate tweets and offensive tweets compared to total tweets\n",
    "monthly_classifications['Hate_Tweet_Percentage'] = (monthly_classifications['Hate_Tweets'] / monthly_classifications['Total_Tweets']) * 100\n",
    "monthly_classifications['Offensive_Tweet_Percentage'] = (monthly_classifications['Offensive_Tweets'] / monthly_classifications['Total_Tweets']) * 100\n",
    "\n",
    "# Create a pivot table for sentiment values\n",
    "# Sentiment is coded as -1=Negative, 0=Neutral, 1=Positive\n",
    "monthly_sentiment_counts = Class22and23df.pivot_table(index='Month_Year', \n",
    "                                                      columns='Sentiment', \n",
    "                                                      aggfunc='size', \n",
    "                                                      fill_value=0).reset_index()\n",
    "#Find average sentiment score of hate tweets \n",
    "# Filter rows where classification is 'Hate' (Classification == 2)\n",
    "hate_tweets_df = Class22and23df[Class22and23df['Classification'] == 2]\n",
    "\n",
    "# Group by 'Month_Year' and calculate the average score for hate tweets\n",
    "hate_tweet_avg_scores = hate_tweets_df.groupby('Month_Year')['Score'].mean().reset_index(name='Avg_Hate_Tweet_Score')\n",
    "\n",
    "# Merge the average hate tweet score into the 'monthly_classifications' DataFrame\n",
    "monthly_classifications = monthly_classifications.merge(hate_tweet_avg_scores, on='Month_Year', how='left')\n",
    "\n",
    "\n",
    "# Rename sentiment columns for better readability\n",
    "monthly_sentiment_counts = monthly_sentiment_counts.rename(columns={-1: 'Negative_Tweets', 0: 'Neutral_Tweets', 1: 'Positive_Tweets'})\n",
    "\n",
    "# Calculate the average sentiment for each month\n",
    "monthly_sentiment_avg = Class22and23df.groupby('Month_Year')['Sentiment'].mean().reset_index(name='Average_Sentiment')\n",
    "\n",
    "# Merge sentiment counts with the average sentiment\n",
    "monthly_sentiment_counts = monthly_sentiment_counts.merge(monthly_sentiment_avg, on='Month_Year', how='left')\n",
    "\n",
    "# Merge sentiment counts into the existing monthly classifications DataFrame\n",
    "monthly_classifications = monthly_classifications.merge(monthly_sentiment_counts, on='Month_Year', how='left')\n",
    "\n",
    "# Set 'Month_Year' as the index\n",
    "monthly_classifications = monthly_classifications.set_index('Month_Year')\n",
    "\n",
    "# Display the ordered monthly figures with Hate Tweets, Offensive Tweets, Neither Tweets, Total Tweets, and Sentiment Counts\n",
    "monthly_classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4436cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Negative_Tweets</th>\n",
       "      <th>Neutral_Tweets</th>\n",
       "      <th>Positive_Tweets</th>\n",
       "      <th>Average_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April 2020</td>\n",
       "      <td>139</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.518367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April 2021</td>\n",
       "      <td>253</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.572104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April 2022</td>\n",
       "      <td>112</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.427273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August 2020</td>\n",
       "      <td>163</td>\n",
       "      <td>111</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.522648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August 2021</td>\n",
       "      <td>155</td>\n",
       "      <td>171</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.394203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>August 2022</td>\n",
       "      <td>92</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.456044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>December 2020</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.284404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>December 2021</td>\n",
       "      <td>174</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.352078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>December 2022</td>\n",
       "      <td>96</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>February 2020</td>\n",
       "      <td>118</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.519608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>February 2021</td>\n",
       "      <td>277</td>\n",
       "      <td>157</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.545652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>February 2022</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.484043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>January 2020</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.459770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>January 2021</td>\n",
       "      <td>223</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>January 2022</td>\n",
       "      <td>141</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.560166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>July 2020</td>\n",
       "      <td>175</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>July 2021</td>\n",
       "      <td>198</td>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.467192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>July 2022</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.420455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>June 2020</td>\n",
       "      <td>358</td>\n",
       "      <td>169</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.626838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>June 2021</td>\n",
       "      <td>210</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.427918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>June 2022</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.494253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>March 2020</td>\n",
       "      <td>132</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>March 2021</td>\n",
       "      <td>528</td>\n",
       "      <td>248</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.613861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>March 2022</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.364486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>May 2020</td>\n",
       "      <td>103</td>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.446078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>May 2021</td>\n",
       "      <td>346</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.542517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>May 2022</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.355649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>November 2020</td>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.449074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>November 2021</td>\n",
       "      <td>173</td>\n",
       "      <td>206</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>November 2022</td>\n",
       "      <td>152</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.470383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>October 2020</td>\n",
       "      <td>99</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.427136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>October 2021</td>\n",
       "      <td>127</td>\n",
       "      <td>178</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>October 2022</td>\n",
       "      <td>168</td>\n",
       "      <td>152</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.448071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>September 2020</td>\n",
       "      <td>151</td>\n",
       "      <td>102</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>September 2021</td>\n",
       "      <td>152</td>\n",
       "      <td>226</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.201814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>September 2022</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.369004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month_Year  Negative_Tweets  Neutral_Tweets  Positive_Tweets  \\\n",
       "0       April 2020              139              94               12   \n",
       "1       April 2021              253             159               11   \n",
       "2       April 2022              112              90               18   \n",
       "3      August 2020              163             111               13   \n",
       "4      August 2021              155             171               19   \n",
       "5      August 2022               92              81                9   \n",
       "6    December 2020               41              58               10   \n",
       "7    December 2021              174             205               30   \n",
       "8    December 2022               96             111                9   \n",
       "9    February 2020              118              74               12   \n",
       "10   February 2021              277             157               26   \n",
       "11   February 2022               95              89                4   \n",
       "12    January 2020               92              70               12   \n",
       "13    January 2021              223             184               13   \n",
       "14    January 2022              141              94                6   \n",
       "15       July 2020              175              96               12   \n",
       "16       July 2021              198             163               20   \n",
       "17       July 2022               84              82               10   \n",
       "18       June 2020              358             169               17   \n",
       "19       June 2021              210             204               23   \n",
       "20       June 2022               97              66               11   \n",
       "21      March 2020              132              68                6   \n",
       "22      March 2021              528             248               32   \n",
       "23      March 2022               95             102               17   \n",
       "24        May 2020              103              89               12   \n",
       "25        May 2021              346             215               27   \n",
       "26        May 2022              107             110               22   \n",
       "27   November 2020              109              95               12   \n",
       "28   November 2021              173             206               29   \n",
       "29   November 2022              152             118               17   \n",
       "30    October 2020               99              86               14   \n",
       "31    October 2021              127             178               25   \n",
       "32    October 2022              168             152               17   \n",
       "33  September 2020              151             102               13   \n",
       "34  September 2021              152             226               63   \n",
       "35  September 2022              126             119               26   \n",
       "\n",
       "    Average_Sentiment  \n",
       "0           -0.518367  \n",
       "1           -0.572104  \n",
       "2           -0.427273  \n",
       "3           -0.522648  \n",
       "4           -0.394203  \n",
       "5           -0.456044  \n",
       "6           -0.284404  \n",
       "7           -0.352078  \n",
       "8           -0.402778  \n",
       "9           -0.519608  \n",
       "10          -0.545652  \n",
       "11          -0.484043  \n",
       "12          -0.459770  \n",
       "13          -0.500000  \n",
       "14          -0.560166  \n",
       "15          -0.575972  \n",
       "16          -0.467192  \n",
       "17          -0.420455  \n",
       "18          -0.626838  \n",
       "19          -0.427918  \n",
       "20          -0.494253  \n",
       "21          -0.611650  \n",
       "22          -0.613861  \n",
       "23          -0.364486  \n",
       "24          -0.446078  \n",
       "25          -0.542517  \n",
       "26          -0.355649  \n",
       "27          -0.449074  \n",
       "28          -0.352941  \n",
       "29          -0.470383  \n",
       "30          -0.427136  \n",
       "31          -0.309091  \n",
       "32          -0.448071  \n",
       "33          -0.518797  \n",
       "34          -0.201814  \n",
       "35          -0.369004  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a98e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_28708\\2012687916.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Year'] = Class22and23df['CreateDate'].str[:4]  # Extract year (first 4 characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_28708\\2012687916.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Num'] = Class22and23df['CreateDate'].str[5:7]  # Extract month number (5th to 7th characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_28708\\2012687916.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month'] = Class22and23df['Month_Num'].map(month_mapping)  # Map month number to month name\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_28708\\2012687916.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Year'] = Class22and23df['Month'] + ' ' + Class22and23df['Year']\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_28708\\2012687916.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Class22and23df['Month_Year_Date'] = pd.to_datetime(Class22and23df['Year'] + '-' + Class22and23df['Month_Num'], format='%Y-%m')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neither_Tweets</th>\n",
       "      <th>Offensive_Tweets</th>\n",
       "      <th>Hate_Tweets</th>\n",
       "      <th>Total_Tweets</th>\n",
       "      <th>Hate_Tweet_Percentage</th>\n",
       "      <th>Offensive_Tweet_Percentage</th>\n",
       "      <th>Negative_Tweets</th>\n",
       "      <th>Neutral_Tweets</th>\n",
       "      <th>Positive_Tweets</th>\n",
       "      <th>Average_Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>January 2020</th>\n",
       "      <td>149</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>10.919540</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.459770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2020</th>\n",
       "      <td>168</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>204</td>\n",
       "      <td>3.921569</td>\n",
       "      <td>13.725490</td>\n",
       "      <td>118</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.519608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2020</th>\n",
       "      <td>168</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>206</td>\n",
       "      <td>1.941748</td>\n",
       "      <td>16.504854</td>\n",
       "      <td>132</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2020</th>\n",
       "      <td>216</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>245</td>\n",
       "      <td>3.673469</td>\n",
       "      <td>8.163265</td>\n",
       "      <td>139</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.518367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2020</th>\n",
       "      <td>161</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>18.137255</td>\n",
       "      <td>103</td>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.446078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2020</th>\n",
       "      <td>406</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>544</td>\n",
       "      <td>10.477941</td>\n",
       "      <td>14.889706</td>\n",
       "      <td>358</td>\n",
       "      <td>169</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.626838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2020</th>\n",
       "      <td>247</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>1.413428</td>\n",
       "      <td>11.307420</td>\n",
       "      <td>175</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2020</th>\n",
       "      <td>251</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>287</td>\n",
       "      <td>1.393728</td>\n",
       "      <td>11.149826</td>\n",
       "      <td>163</td>\n",
       "      <td>111</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.522648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2020</th>\n",
       "      <td>242</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>1.127820</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>151</td>\n",
       "      <td>102</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.518797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2020</th>\n",
       "      <td>175</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>1.507538</td>\n",
       "      <td>10.552764</td>\n",
       "      <td>99</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.427136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2020</th>\n",
       "      <td>192</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>10.648148</td>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.449074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2020</th>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>1.834862</td>\n",
       "      <td>7.339450</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.284404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January 2021</th>\n",
       "      <td>368</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>11.904762</td>\n",
       "      <td>223</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2021</th>\n",
       "      <td>401</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>11.739130</td>\n",
       "      <td>277</td>\n",
       "      <td>157</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.545652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2021</th>\n",
       "      <td>688</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>808</td>\n",
       "      <td>2.351485</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>528</td>\n",
       "      <td>248</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.613861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2021</th>\n",
       "      <td>363</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>423</td>\n",
       "      <td>2.836879</td>\n",
       "      <td>11.347518</td>\n",
       "      <td>253</td>\n",
       "      <td>159</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.572104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2021</th>\n",
       "      <td>519</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>588</td>\n",
       "      <td>4.421769</td>\n",
       "      <td>7.312925</td>\n",
       "      <td>346</td>\n",
       "      <td>215</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.542517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2021</th>\n",
       "      <td>390</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>437</td>\n",
       "      <td>0.686499</td>\n",
       "      <td>10.068650</td>\n",
       "      <td>210</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.427918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2021</th>\n",
       "      <td>341</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>381</td>\n",
       "      <td>1.049869</td>\n",
       "      <td>9.448819</td>\n",
       "      <td>198</td>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.467192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2021</th>\n",
       "      <td>310</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>345</td>\n",
       "      <td>3.188406</td>\n",
       "      <td>6.956522</td>\n",
       "      <td>155</td>\n",
       "      <td>171</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.394203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2021</th>\n",
       "      <td>415</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>441</td>\n",
       "      <td>1.133787</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>152</td>\n",
       "      <td>226</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.201814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2021</th>\n",
       "      <td>309</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>330</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>127</td>\n",
       "      <td>178</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.309091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2021</th>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>408</td>\n",
       "      <td>2.205882</td>\n",
       "      <td>5.392157</td>\n",
       "      <td>173</td>\n",
       "      <td>206</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2021</th>\n",
       "      <td>370</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>409</td>\n",
       "      <td>3.422983</td>\n",
       "      <td>6.112469</td>\n",
       "      <td>174</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.352078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January 2022</th>\n",
       "      <td>213</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>2.074689</td>\n",
       "      <td>9.543568</td>\n",
       "      <td>141</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.560166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February 2022</th>\n",
       "      <td>169</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>9.042553</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.484043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March 2022</th>\n",
       "      <td>194</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>214</td>\n",
       "      <td>2.336449</td>\n",
       "      <td>7.009346</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.364486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April 2022</th>\n",
       "      <td>206</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>220</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>112</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.427273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May 2022</th>\n",
       "      <td>216</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "      <td>1.255230</td>\n",
       "      <td>8.368201</td>\n",
       "      <td>107</td>\n",
       "      <td>110</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.355649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June 2022</th>\n",
       "      <td>157</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.770115</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.494253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 2022</th>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.420455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August 2022</th>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>182</td>\n",
       "      <td>5.494505</td>\n",
       "      <td>4.945055</td>\n",
       "      <td>92</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.456044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September 2022</th>\n",
       "      <td>248</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>271</td>\n",
       "      <td>0.738007</td>\n",
       "      <td>7.749077</td>\n",
       "      <td>126</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.369004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October 2022</th>\n",
       "      <td>290</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>337</td>\n",
       "      <td>1.483680</td>\n",
       "      <td>12.462908</td>\n",
       "      <td>168</td>\n",
       "      <td>152</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.448071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November 2022</th>\n",
       "      <td>260</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>287</td>\n",
       "      <td>2.090592</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>152</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.470383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December 2022</th>\n",
       "      <td>185</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>96</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.402778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Neither_Tweets  Offensive_Tweets  Hate_Tweets  Total_Tweets  \\\n",
       "Month_Year                                                                    \n",
       "January 2020               149                19            6           174   \n",
       "February 2020              168                28            8           204   \n",
       "March 2020                 168                34            4           206   \n",
       "April 2020                 216                20            9           245   \n",
       "May 2020                   161                37            6           204   \n",
       "June 2020                  406                81           57           544   \n",
       "July 2020                  247                32            4           283   \n",
       "August 2020                251                32            4           287   \n",
       "September 2020             242                21            3           266   \n",
       "October 2020               175                21            3           199   \n",
       "November 2020              192                23            1           216   \n",
       "December 2020               99                 8            2           109   \n",
       "January 2021               368                50            2           420   \n",
       "February 2021              401                54            5           460   \n",
       "March 2021                 688               101           19           808   \n",
       "April 2021                 363                48           12           423   \n",
       "May 2021                   519                43           26           588   \n",
       "June 2021                  390                44            3           437   \n",
       "July 2021                  341                36            4           381   \n",
       "August 2021                310                24           11           345   \n",
       "September 2021             415                21            5           441   \n",
       "October 2021               309                12            9           330   \n",
       "November 2021              377                22            9           408   \n",
       "December 2021              370                25           14           409   \n",
       "January 2022               213                23            5           241   \n",
       "February 2022              169                17            2           188   \n",
       "March 2022                 194                15            5           214   \n",
       "April 2022                 206                 7            7           220   \n",
       "May 2022                   216                20            3           239   \n",
       "June 2022                  157                17            0           174   \n",
       "July 2022                  151                24            1           176   \n",
       "August 2022                163                 9           10           182   \n",
       "September 2022             248                21            2           271   \n",
       "October 2022               290                42            5           337   \n",
       "November 2022              260                21            6           287   \n",
       "December 2022              185                30            1           216   \n",
       "\n",
       "                Hate_Tweet_Percentage  Offensive_Tweet_Percentage  \\\n",
       "Month_Year                                                          \n",
       "January 2020                 3.448276                   10.919540   \n",
       "February 2020                3.921569                   13.725490   \n",
       "March 2020                   1.941748                   16.504854   \n",
       "April 2020                   3.673469                    8.163265   \n",
       "May 2020                     2.941176                   18.137255   \n",
       "June 2020                   10.477941                   14.889706   \n",
       "July 2020                    1.413428                   11.307420   \n",
       "August 2020                  1.393728                   11.149826   \n",
       "September 2020               1.127820                    7.894737   \n",
       "October 2020                 1.507538                   10.552764   \n",
       "November 2020                0.462963                   10.648148   \n",
       "December 2020                1.834862                    7.339450   \n",
       "January 2021                 0.476190                   11.904762   \n",
       "February 2021                1.086957                   11.739130   \n",
       "March 2021                   2.351485                   12.500000   \n",
       "April 2021                   2.836879                   11.347518   \n",
       "May 2021                     4.421769                    7.312925   \n",
       "June 2021                    0.686499                   10.068650   \n",
       "July 2021                    1.049869                    9.448819   \n",
       "August 2021                  3.188406                    6.956522   \n",
       "September 2021               1.133787                    4.761905   \n",
       "October 2021                 2.727273                    3.636364   \n",
       "November 2021                2.205882                    5.392157   \n",
       "December 2021                3.422983                    6.112469   \n",
       "January 2022                 2.074689                    9.543568   \n",
       "February 2022                1.063830                    9.042553   \n",
       "March 2022                   2.336449                    7.009346   \n",
       "April 2022                   3.181818                    3.181818   \n",
       "May 2022                     1.255230                    8.368201   \n",
       "June 2022                    0.000000                    9.770115   \n",
       "July 2022                    0.568182                   13.636364   \n",
       "August 2022                  5.494505                    4.945055   \n",
       "September 2022               0.738007                    7.749077   \n",
       "October 2022                 1.483680                   12.462908   \n",
       "November 2022                2.090592                    7.317073   \n",
       "December 2022                0.462963                   13.888889   \n",
       "\n",
       "                Negative_Tweets  Neutral_Tweets  Positive_Tweets  \\\n",
       "Month_Year                                                         \n",
       "January 2020                 92              70               12   \n",
       "February 2020               118              74               12   \n",
       "March 2020                  132              68                6   \n",
       "April 2020                  139              94               12   \n",
       "May 2020                    103              89               12   \n",
       "June 2020                   358             169               17   \n",
       "July 2020                   175              96               12   \n",
       "August 2020                 163             111               13   \n",
       "September 2020              151             102               13   \n",
       "October 2020                 99              86               14   \n",
       "November 2020               109              95               12   \n",
       "December 2020                41              58               10   \n",
       "January 2021                223             184               13   \n",
       "February 2021               277             157               26   \n",
       "March 2021                  528             248               32   \n",
       "April 2021                  253             159               11   \n",
       "May 2021                    346             215               27   \n",
       "June 2021                   210             204               23   \n",
       "July 2021                   198             163               20   \n",
       "August 2021                 155             171               19   \n",
       "September 2021              152             226               63   \n",
       "October 2021                127             178               25   \n",
       "November 2021               173             206               29   \n",
       "December 2021               174             205               30   \n",
       "January 2022                141              94                6   \n",
       "February 2022                95              89                4   \n",
       "March 2022                   95             102               17   \n",
       "April 2022                  112              90               18   \n",
       "May 2022                    107             110               22   \n",
       "June 2022                    97              66               11   \n",
       "July 2022                    84              82               10   \n",
       "August 2022                  92              81                9   \n",
       "September 2022              126             119               26   \n",
       "October 2022                168             152               17   \n",
       "November 2022               152             118               17   \n",
       "December 2022                96             111                9   \n",
       "\n",
       "                Average_Sentiment  \n",
       "Month_Year                         \n",
       "January 2020            -0.459770  \n",
       "February 2020           -0.519608  \n",
       "March 2020              -0.611650  \n",
       "April 2020              -0.518367  \n",
       "May 2020                -0.446078  \n",
       "June 2020               -0.626838  \n",
       "July 2020               -0.575972  \n",
       "August 2020             -0.522648  \n",
       "September 2020          -0.518797  \n",
       "October 2020            -0.427136  \n",
       "November 2020           -0.449074  \n",
       "December 2020           -0.284404  \n",
       "January 2021            -0.500000  \n",
       "February 2021           -0.545652  \n",
       "March 2021              -0.613861  \n",
       "April 2021              -0.572104  \n",
       "May 2021                -0.542517  \n",
       "June 2021               -0.427918  \n",
       "July 2021               -0.467192  \n",
       "August 2021             -0.394203  \n",
       "September 2021          -0.201814  \n",
       "October 2021            -0.309091  \n",
       "November 2021           -0.352941  \n",
       "December 2021           -0.352078  \n",
       "January 2022            -0.560166  \n",
       "February 2022           -0.484043  \n",
       "March 2022              -0.364486  \n",
       "April 2022              -0.427273  \n",
       "May 2022                -0.355649  \n",
       "June 2022               -0.494253  \n",
       "July 2022               -0.420455  \n",
       "August 2022             -0.456044  \n",
       "September 2022          -0.369004  \n",
       "October 2022            -0.448071  \n",
       "November 2022           -0.470383  \n",
       "December 2022           -0.402778  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of month numbers to names\n",
    "month_mapping = {\n",
    "    '01': 'January', '02': 'February', '03': 'March', '04': 'April',\n",
    "    '05': 'May', '06': 'June', '07': 'July', '08': 'August',\n",
    "    '09': 'September', '10': 'October', '11': 'November', '12': 'December'\n",
    "}\n",
    "\n",
    "# Extract the year and month as strings\n",
    "Class22and23df['Year'] = Class22and23df['CreateDate'].str[:4]  # Extract year (first 4 characters)\n",
    "Class22and23df['Month_Num'] = Class22and23df['CreateDate'].str[5:7]  # Extract month number (5th to 7th characters)\n",
    "Class22and23df['Month'] = Class22and23df['Month_Num'].map(month_mapping)  # Map month number to month name\n",
    "\n",
    "# Combine year and month into one column\n",
    "Class22and23df['Month_Year'] = Class22and23df['Month'] + ' ' + Class22and23df['Year']\n",
    "\n",
    "# Convert 'Month_Year' to a datetime object for proper sorting\n",
    "Class22and23df['Month_Year_Date'] = pd.to_datetime(Class22and23df['Year'] + '-' + Class22and23df['Month_Num'], format='%Y-%m')\n",
    "\n",
    "# Create a pivot table to split the 'Classification' values\n",
    "# Count tweets for each classification (-1=Neither, 0=Offensive, 1=Hate) per month\n",
    "monthly_classifications = Class22and23df.pivot_table(index=['Month_Year', 'Month_Year_Date'],\n",
    "                                                     columns='Classification',\n",
    "                                                     aggfunc='size',\n",
    "                                                     fill_value=0).reset_index()\n",
    "\n",
    "# Rename the columns for better readability\n",
    "monthly_classifications = monthly_classifications.rename(columns={0: 'Neither_Tweets', 1: 'Offensive_Tweets', 2: 'Hate_Tweets'})\n",
    "\n",
    "# Sort the data by 'Month_Year_Date' to ensure proper date order\n",
    "monthly_classifications = monthly_classifications.sort_values(by='Month_Year_Date').drop(columns='Month_Year_Date')\n",
    "\n",
    "# Add a new column 'Total_Tweets' for the total count of tweets per month\n",
    "monthly_classifications['Total_Tweets'] = monthly_classifications[['Neither_Tweets', 'Offensive_Tweets', 'Hate_Tweets']].sum(axis=1)\n",
    "\n",
    "# Calculate the percentage of hate tweets and offensive tweets compared to total tweets\n",
    "monthly_classifications['Hate_Tweet_Percentage'] = (monthly_classifications['Hate_Tweets'] / monthly_classifications['Total_Tweets']) * 100\n",
    "monthly_classifications['Offensive_Tweet_Percentage'] = (monthly_classifications['Offensive_Tweets'] / monthly_classifications['Total_Tweets']) * 100\n",
    "\n",
    "# Create a pivot table for sentiment values\n",
    "# Sentiment is coded as -1=Negative, 0=Neutral, 1=Positive\n",
    "monthly_sentiment_counts = Class22and23df.pivot_table(index='Month_Year', \n",
    "                                                      columns='Sentiment', \n",
    "                                                      aggfunc='size', \n",
    "                                                      fill_value=0).reset_index()\n",
    "\n",
    "# Rename sentiment columns for better readability\n",
    "monthly_sentiment_counts = monthly_sentiment_counts.rename(columns= {-1: 'Negative_Tweets', 0: 'Neutral_Tweets', 1: 'Positive_Tweets'})\n",
    "\n",
    "# Calculate the average sentiment for each month\n",
    "monthly_sentiment_avg = Class22and23df.groupby('Month_Year')['Sentiment'].mean().reset_index(name='Average_Sentiment')\n",
    "\n",
    "# Merge sentiment counts with the average sentiment\n",
    "monthly_sentiment_counts = monthly_sentiment_counts.merge(monthly_sentiment_avg, on='Month_Year', how='left')\n",
    "\n",
    "# Merge sentiment counts into the existing monthly classifications DataFrame\n",
    "monthly_classifications = monthly_classifications.merge(monthly_sentiment_counts, on='Month_Year', how='left')\n",
    "\n",
    "# Set 'Month_Year' as the index\n",
    "monthly_classifications = monthly_classifications.set_index('Month_Year')\n",
    "\n",
    "# Display the ordered monthly figures with Hate Tweets, Offensive Tweets, Neither Tweets, Total Tweets, and Sentiment Counts\n",
    "monthly_classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f281ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_classifications.to_csv('MonthlySent20To22')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98801475",
   "metadata": {},
   "source": [
    "## Euro Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef450f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eurodf = pd.read_csv('Euro_tweets_HMB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c095dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>meta.type</th>\n",
       "      <th>meta.date</th>\n",
       "      <th>hate</th>\n",
       "      <th>meta.lang</th>\n",
       "      <th>nuts2</th>\n",
       "      <th>meta.nuts3</th>\n",
       "      <th>hateful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T08:13:42.000Z</td>\n",
       "      <td>0.16</td>\n",
       "      <td>de</td>\n",
       "      <td>AT13</td>\n",
       "      <td>AT130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T06:22:08.000Z</td>\n",
       "      <td>0.05</td>\n",
       "      <td>de</td>\n",
       "      <td>AT33</td>\n",
       "      <td>AT332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        meta.type                 meta.date  hate meta.lang nuts2  \\\n",
       "0   0  twitter_comment  2018-09-19T08:13:42.000Z  0.16        de  AT13   \n",
       "1   1  twitter_comment  2018-09-19T06:22:08.000Z  0.05        de  AT33   \n",
       "\n",
       "  meta.nuts3  hateful  \n",
       "0      AT130        0  \n",
       "1      AT332        0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eurodf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e76d8cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>meta.type</th>\n",
       "      <th>meta.date</th>\n",
       "      <th>hate</th>\n",
       "      <th>meta.lang</th>\n",
       "      <th>nuts2</th>\n",
       "      <th>meta.nuts3</th>\n",
       "      <th>hateful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T11:53:38.000Z</td>\n",
       "      <td>0.10</td>\n",
       "      <td>en</td>\n",
       "      <td>UKI5</td>\n",
       "      <td>UKI51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T11:33:03.000Z</td>\n",
       "      <td>0.00</td>\n",
       "      <td>en</td>\n",
       "      <td>UKE1</td>\n",
       "      <td>UKE13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T11:32:53.000Z</td>\n",
       "      <td>0.07</td>\n",
       "      <td>en</td>\n",
       "      <td>UKK1</td>\n",
       "      <td>UKK11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T11:29:08.000Z</td>\n",
       "      <td>0.83</td>\n",
       "      <td>en</td>\n",
       "      <td>UKK4</td>\n",
       "      <td>UKK43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2018-09-19T11:24:39.000Z</td>\n",
       "      <td>0.69</td>\n",
       "      <td>en</td>\n",
       "      <td>UKM6</td>\n",
       "      <td>UKM61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882341</th>\n",
       "      <td>882341</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2019-01-13T13:05:59.000Z</td>\n",
       "      <td>0.13</td>\n",
       "      <td>en</td>\n",
       "      <td>UKI5</td>\n",
       "      <td>UKI54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882342</th>\n",
       "      <td>882342</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2019-01-13T13:05:58.000Z</td>\n",
       "      <td>0.10</td>\n",
       "      <td>en</td>\n",
       "      <td>UKI5</td>\n",
       "      <td>UKI54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882343</th>\n",
       "      <td>882343</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2019-01-13T12:49:27.000Z</td>\n",
       "      <td>0.03</td>\n",
       "      <td>en</td>\n",
       "      <td>UKI3</td>\n",
       "      <td>UKI33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882344</th>\n",
       "      <td>882344</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2019-01-13T12:47:39.000Z</td>\n",
       "      <td>0.16</td>\n",
       "      <td>en</td>\n",
       "      <td>UKI7</td>\n",
       "      <td>UKI75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882345</th>\n",
       "      <td>882345</td>\n",
       "      <td>twitter_comment</td>\n",
       "      <td>2019-01-13T12:01:04.000Z</td>\n",
       "      <td>0.33</td>\n",
       "      <td>en</td>\n",
       "      <td>UKJ2</td>\n",
       "      <td>UKJ26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286877 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id        meta.type                 meta.date  hate meta.lang  \\\n",
       "83          83  twitter_comment  2018-09-19T11:53:38.000Z  0.10        en   \n",
       "84          84  twitter_comment  2018-09-19T11:33:03.000Z  0.00        en   \n",
       "85          85  twitter_comment  2018-09-19T11:32:53.000Z  0.07        en   \n",
       "86          86  twitter_comment  2018-09-19T11:29:08.000Z  0.83        en   \n",
       "87          87  twitter_comment  2018-09-19T11:24:39.000Z  0.69        en   \n",
       "...        ...              ...                       ...   ...       ...   \n",
       "882341  882341  twitter_comment  2019-01-13T13:05:59.000Z  0.13        en   \n",
       "882342  882342  twitter_comment  2019-01-13T13:05:58.000Z  0.10        en   \n",
       "882343  882343  twitter_comment  2019-01-13T12:49:27.000Z  0.03        en   \n",
       "882344  882344  twitter_comment  2019-01-13T12:47:39.000Z  0.16        en   \n",
       "882345  882345  twitter_comment  2019-01-13T12:01:04.000Z  0.33        en   \n",
       "\n",
       "       nuts2 meta.nuts3  hateful  \n",
       "83      UKI5      UKI51        0  \n",
       "84      UKE1      UKE13        0  \n",
       "85      UKK1      UKK11        0  \n",
       "86      UKK4      UKK43        1  \n",
       "87      UKM6      UKM61        1  \n",
       "...      ...        ...      ...  \n",
       "882341  UKI5      UKI54        0  \n",
       "882342  UKI5      UKI54        0  \n",
       "882343  UKI3      UKI33        0  \n",
       "882344  UKI7      UKI75        0  \n",
       "882345  UKJ2      UKJ26        0  \n",
       "\n",
       "[286877 rows x 8 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to show only rows where the 'nuts2' column starts with 'UK'\n",
    "df_en = Eurodf[Eurodf['nuts2'].str.startswith('UK', na=False)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "df_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e5cca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.to_csv('UK_tweets_HMB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b822358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    233954\n",
       "1     52923\n",
       "Name: hateful, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en['hateful'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afece57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_12400\\2313685967.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['Year'] = df_en['meta.date'].str[:4]  # Extract year (first 4 characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_12400\\2313685967.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['Month_Num'] = df_en['meta.date'].str[5:7]  # Extract month number (5th to 7th characters)\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_12400\\2313685967.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['Month'] = df_en['Month_Num'].map(month_mapping)  # Map month number to month name\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_12400\\2313685967.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['Month_Year'] = df_en['Month'] + ' ' + df_en['Year']\n",
      "C:\\Users\\Shaun\\AppData\\Local\\Temp\\ipykernel_12400\\2313685967.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['Month_Year_Date'] = pd.to_datetime(df_en['Year'] + '-' + df_en['Month_Num'], format='%Y-%m')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_Year</th>\n",
       "      <th>Hate_Tweets</th>\n",
       "      <th>Total_Tweets</th>\n",
       "      <th>Hate_Tweet_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January 2015</td>\n",
       "      <td>243</td>\n",
       "      <td>1101</td>\n",
       "      <td>22.070845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 2015</td>\n",
       "      <td>235</td>\n",
       "      <td>1130</td>\n",
       "      <td>20.796460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March 2015</td>\n",
       "      <td>376</td>\n",
       "      <td>1745</td>\n",
       "      <td>21.547278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April 2015</td>\n",
       "      <td>880</td>\n",
       "      <td>4290</td>\n",
       "      <td>20.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 2015</td>\n",
       "      <td>562</td>\n",
       "      <td>2805</td>\n",
       "      <td>20.035651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>August 2020</td>\n",
       "      <td>1795</td>\n",
       "      <td>8225</td>\n",
       "      <td>21.823708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>September 2020</td>\n",
       "      <td>731</td>\n",
       "      <td>3360</td>\n",
       "      <td>21.755952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>October 2020</td>\n",
       "      <td>540</td>\n",
       "      <td>2782</td>\n",
       "      <td>19.410496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>November 2020</td>\n",
       "      <td>379</td>\n",
       "      <td>1950</td>\n",
       "      <td>19.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>December 2020</td>\n",
       "      <td>383</td>\n",
       "      <td>1930</td>\n",
       "      <td>19.844560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month_Year  Hate_Tweets  Total_Tweets  Hate_Tweet_Percentage\n",
       "0     January 2015          243          1101              22.070845\n",
       "1    February 2015          235          1130              20.796460\n",
       "2       March 2015          376          1745              21.547278\n",
       "3       April 2015          880          4290              20.512821\n",
       "4         May 2015          562          2805              20.035651\n",
       "..             ...          ...           ...                    ...\n",
       "67     August 2020         1795          8225              21.823708\n",
       "68  September 2020          731          3360              21.755952\n",
       "69    October 2020          540          2782              19.410496\n",
       "70   November 2020          379          1950              19.435897\n",
       "71   December 2020          383          1930              19.844560\n",
       "\n",
       "[72 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a mapping of month numbers to names\n",
    "month_mapping = {\n",
    "    '01': 'January', '02': 'February', '03': 'March', '04': 'April',\n",
    "    '05': 'May', '06': 'June', '07': 'July', '08': 'August',\n",
    "    '09': 'September', '10': 'October', '11': 'November', '12': 'December'\n",
    "}\n",
    "\n",
    "# Extract the year and month as strings\n",
    "df_en['Year'] = df_en['meta.date'].str[:4]  # Extract year (first 4 characters)\n",
    "df_en['Month_Num'] = df_en['meta.date'].str[5:7]  # Extract month number (5th to 7th characters)\n",
    "df_en['Month'] = df_en['Month_Num'].map(month_mapping)  # Map month number to month name\n",
    "\n",
    "# Combine year and month into one column\n",
    "df_en['Month_Year'] = df_en['Month'] + ' ' + df_en['Year']\n",
    "\n",
    "# Convert 'Month_Year' to a datetime object for proper sorting\n",
    "df_en['Month_Year_Date'] = pd.to_datetime(df_en['Year'] + '-' + df_en['Month_Num'], format='%Y-%m')\n",
    "\n",
    "# Group by 'Month_Year' and 'Month_Year_Date', summing the 'hateful' tweets\n",
    "monthly_hateTweets = df_en.groupby(['Month_Year', 'Month_Year_Date'])['hateful'].sum().reset_index()\n",
    "\n",
    "# Rename 'hateful' to 'Hate_Tweets'\n",
    "monthly_hateTweets = monthly_hateTweets.rename({'hateful': 'Hate_Tweets'}, axis=1)\n",
    "\n",
    "# Sort the data by 'Month_Year_Date' to ensure proper date order\n",
    "monthly_hateTweets = monthly_hateTweets.sort_values(by='Month_Year_Date').drop(columns='Month_Year_Date')\n",
    "\n",
    "# Add a new column 'Total_Tweets' for the total count of tweets per month\n",
    "# Ensure we use .size() instead of .count() for the number of tweets\n",
    "monthly_tweet_counts = df_en.groupby('Month_Year').size().reset_index(name='Total_Tweets')\n",
    "\n",
    "# Merge 'Total_Tweets' into the 'monthly_hateTweets' DataFrame\n",
    "monthly_hateTweets = pd.merge(monthly_hateTweets, monthly_tweet_counts, on='Month_Year')\n",
    "\n",
    "# Calculate the percentage of hate tweets compared to total tweets\n",
    "monthly_hateTweets['Hate_Tweet_Percentage'] = (monthly_hateTweets['Hate_Tweets'] / monthly_hateTweets['Total_Tweets']) * 100\n",
    "\n",
    "\n",
    "# Display the ordered monthly figures with Hate Tweets and Total Tweets\n",
    "monthly_hateTweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61406410",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monthly_hateTweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmonthly_hateTweets\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUkmonthly2015\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'monthly_hateTweets' is not defined"
     ]
    }
   ],
   "source": [
    "monthly_hateTweets.to_csv('Ukmonthly2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fab884",
   "metadata": {},
   "source": [
    "## BREXIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9046594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Key Phrases</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Alternate Date Format</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-Jan-2022 11:58PM</td>\n",
       "      <td>RT @re11ddy: QT @sandieshoes: Do this if you v...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:58 PM</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-Jan-2022 11:57PM</td>\n",
       "      <td>RT @RickSacrop: Michael Fabricant is absolutel...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>hell bent,precious EU</td>\n",
       "      <td>EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:57 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Jan-2022 11:56PM</td>\n",
       "      <td>@StokieDrew2 I do find it rich; that Tory vote...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson leadership,Tory voters</td>\n",
       "      <td>Brexit,EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:56 PM</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>Belfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Jan-2022 11:54PM</td>\n",
       "      <td>RT @denistmurray: Brexit Britain win as London...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best city</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:54 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-Jan-2022 11:53PM</td>\n",
       "      <td>@afneil If Johnson is taken down by The Tories...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>credible Brexiteer,droves,likelihood</td>\n",
       "      <td>Brexiteers,Brexiteer</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:53 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147626</th>\n",
       "      <td>20-Mar-2022 12:01AM</td>\n",
       "      <td>@JamesRobvincent @7nestingwrens He was also fi...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Tory party,main man,rough ride,undemocratic EU</td>\n",
       "      <td>EU</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:01 AM</td>\n",
       "      <td>England</td>\n",
       "      <td>Lichfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147627</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>RT @sandieshoes: Boris is being heavily critic...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>country,famous recent example,fight for freedo...</td>\n",
       "      <td>Brexit,EU</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Bristol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147628</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>Ludicrous to suggest Boris is insulting Ukrain...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>European</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147629</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>RT @DannyInvictus: @timfarron @ThomasEvansAdur...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>freedom,passionate defence,support,vaccine tas...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147630</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>QT @LindaBr07293431: Poor carowhine her bitter...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advances,bitter unhealthy obsession,great spee...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147631 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0       15-Jan-2022 11:58PM   \n",
       "1       15-Jan-2022 11:57PM   \n",
       "2       15-Jan-2022 11:56PM   \n",
       "3       15-Jan-2022 11:54PM   \n",
       "4       15-Jan-2022 11:53PM   \n",
       "...                     ...   \n",
       "147626  20-Mar-2022 12:01AM   \n",
       "147627  20-Mar-2022 12:00AM   \n",
       "147628  20-Mar-2022 12:00AM   \n",
       "147629  20-Mar-2022 12:00AM   \n",
       "147630  20-Mar-2022 12:00AM   \n",
       "\n",
       "                                                     Text   Source  \\\n",
       "0       RT @re11ddy: QT @sandieshoes: Do this if you v...  Twitter   \n",
       "1       RT @RickSacrop: Michael Fabricant is absolutel...  Twitter   \n",
       "2       @StokieDrew2 I do find it rich; that Tory vote...  Twitter   \n",
       "3       RT @denistmurray: Brexit Britain win as London...  Twitter   \n",
       "4       @afneil If Johnson is taken down by The Tories...  Twitter   \n",
       "...                                                   ...      ...   \n",
       "147626  @JamesRobvincent @7nestingwrens He was also fi...  Twitter   \n",
       "147627  RT @sandieshoes: Boris is being heavily critic...  Twitter   \n",
       "147628  Ludicrous to suggest Boris is insulting Ukrain...  Twitter   \n",
       "147629  RT @DannyInvictus: @timfarron @ThomasEvansAdur...  Twitter   \n",
       "147630  QT @LindaBr07293431: Poor carowhine her bitter...  Twitter   \n",
       "\n",
       "               Country  Subregion Language Sentiment  \\\n",
       "0             Cameroon        NaN  English   Neutral   \n",
       "1       United Kingdom        NaN  English  Negative   \n",
       "2       United Kingdom        NaN  English  Negative   \n",
       "3       United Kingdom        NaN  English  Positive   \n",
       "4       United Kingdom        NaN  English   Neutral   \n",
       "...                ...        ...      ...       ...   \n",
       "147626  United Kingdom        NaN  English   Neutral   \n",
       "147627   United States        NaN  English   Neutral   \n",
       "147628         Unknown        NaN  English  Negative   \n",
       "147629  United Kingdom        NaN  English  Negative   \n",
       "147630         Unknown        NaN  English  Positive   \n",
       "\n",
       "                                              Key Phrases  \\\n",
       "0                                                     NaN   \n",
       "1                                   hell bent,precious EU   \n",
       "2                          Johnson leadership,Tory voters   \n",
       "3                                               best city   \n",
       "4                    credible Brexiteer,droves,likelihood   \n",
       "...                                                   ...   \n",
       "147626     Tory party,main man,rough ride,undemocratic EU   \n",
       "147627  country,famous recent example,fight for freedo...   \n",
       "147628                                                NaN   \n",
       "147629  freedom,passionate defence,support,vaccine tas...   \n",
       "147630  advances,bitter unhealthy obsession,great spee...   \n",
       "\n",
       "                    Keywords Alternate Date Format      Time  \\\n",
       "0                     Brexit          Jan 15, 2022  11:58 PM   \n",
       "1                         EU          Jan 15, 2022  11:57 PM   \n",
       "2                  Brexit,EU          Jan 15, 2022  11:56 PM   \n",
       "3                     Brexit          Jan 15, 2022  11:54 PM   \n",
       "4       Brexiteers,Brexiteer          Jan 15, 2022  11:53 PM   \n",
       "...                      ...                   ...       ...   \n",
       "147626                    EU          Mar 20, 2022  12:01 AM   \n",
       "147627             Brexit,EU          Mar 20, 2022  12:00 AM   \n",
       "147628              European          Mar 20, 2022  12:00 AM   \n",
       "147629                Brexit          Mar 20, 2022  12:00 AM   \n",
       "147630                Brexit          Mar 20, 2022  12:00 AM   \n",
       "\n",
       "                   State       City  \n",
       "0                  North        NaN  \n",
       "1                England        NaN  \n",
       "2       Northern Ireland    Belfast  \n",
       "3                    NaN        NaN  \n",
       "4                England        NaN  \n",
       "...                  ...        ...  \n",
       "147626           England  Lichfield  \n",
       "147627      Pennsylvania    Bristol  \n",
       "147628               NaN        NaN  \n",
       "147629           England     London  \n",
       "147630               NaN        NaN  \n",
       "\n",
       "[147631 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brexitdf = pd.read_csv('TweetDataset_ProBrexit_Jan-Mar2022.csv', delimiter=',')\n",
    "Brexitdf =Brexitdf.drop(columns=['Input Name','Reddit Social Echo', 'National Viewership', 'Desktop Reach', 'Mobile Reach', 'Twitter Social Echo', 'Facebook Social Echo', 'Engagement', 'AVE', 'Twitter Authority', 'Tweet Id', 'Twitter Id', 'Twitter Client', 'Reach','Influencer', 'User Profile Url', 'Headline','URL','Opening Text', 'Document Tags', 'Twitter Bio','Twitter Followers','Twitter Following', 'Twitter Screen Name', 'Unnamed: 0'])\n",
    "Brexitdf = Brexitdf.rename(columns= {'Hit Sentence':'Text'})\n",
    "Brexitdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169fa946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list(Brexitdf['Text'])\n",
    "# Run the preprocessing function\n",
    "clean_tweet = preprocess(tweet_list)\n",
    "Brexitdf['Text']= clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c984e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Key Phrases</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Alternate Date Format</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-Jan-2022 11:58PM</td>\n",
       "      <td>qt value brexit ; tory mp back constituency we...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:58 PM</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-Jan-2022 11:57PM</td>\n",
       "      <td>michael fabricant absolutely right dangerous e...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>hell bent,precious EU</td>\n",
       "      <td>EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:57 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Jan-2022 11:56PM</td>\n",
       "      <td>find rich ; tory voter assume unionists/conser...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson leadership,Tory voters</td>\n",
       "      <td>Brexit,EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:56 PM</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>Belfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Jan-2022 11:54PM</td>\n",
       "      <td>brexit britain win london named best city youn...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best city</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:54 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-Jan-2022 11:53PM</td>\n",
       "      <td>johnson taken tory likelihood imposed pm remai...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>credible Brexiteer,droves,likelihood</td>\n",
       "      <td>Brexiteers,Brexiteer</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:53 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147626</th>\n",
       "      <td>20-Mar-2022 12:01AM</td>\n",
       "      <td>also fighting tory party time😢 really main man...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Tory party,main man,rough ride,undemocratic EU</td>\n",
       "      <td>EU</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:01 AM</td>\n",
       "      <td>England</td>\n",
       "      <td>Lichfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147627</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>boris heavily criticised saying ‘ instinct peo...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>country,famous recent example,fight for freedo...</td>\n",
       "      <td>Brexit,EU</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Bristol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147628</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>ludicrous suggest boris insulting ukrainian gi...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>European</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147629</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>’ worth johnson actually making passionate def...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>freedom,passionate defence,support,vaccine tas...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147630</th>\n",
       "      <td>20-Mar-2022 12:00AM</td>\n",
       "      <td>qt poor carowhine bitter unhealthy obsession p...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advances,bitter unhealthy obsession,great spee...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Mar 20, 2022</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147631 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0       15-Jan-2022 11:58PM   \n",
       "1       15-Jan-2022 11:57PM   \n",
       "2       15-Jan-2022 11:56PM   \n",
       "3       15-Jan-2022 11:54PM   \n",
       "4       15-Jan-2022 11:53PM   \n",
       "...                     ...   \n",
       "147626  20-Mar-2022 12:01AM   \n",
       "147627  20-Mar-2022 12:00AM   \n",
       "147628  20-Mar-2022 12:00AM   \n",
       "147629  20-Mar-2022 12:00AM   \n",
       "147630  20-Mar-2022 12:00AM   \n",
       "\n",
       "                                                     Text   Source  \\\n",
       "0       qt value brexit ; tory mp back constituency we...  Twitter   \n",
       "1       michael fabricant absolutely right dangerous e...  Twitter   \n",
       "2       find rich ; tory voter assume unionists/conser...  Twitter   \n",
       "3       brexit britain win london named best city youn...  Twitter   \n",
       "4       johnson taken tory likelihood imposed pm remai...  Twitter   \n",
       "...                                                   ...      ...   \n",
       "147626  also fighting tory party time😢 really main man...  Twitter   \n",
       "147627  boris heavily criticised saying ‘ instinct peo...  Twitter   \n",
       "147628  ludicrous suggest boris insulting ukrainian gi...  Twitter   \n",
       "147629  ’ worth johnson actually making passionate def...  Twitter   \n",
       "147630  qt poor carowhine bitter unhealthy obsession p...  Twitter   \n",
       "\n",
       "               Country  Subregion Language Sentiment  \\\n",
       "0             Cameroon        NaN  English   Neutral   \n",
       "1       United Kingdom        NaN  English  Negative   \n",
       "2       United Kingdom        NaN  English  Negative   \n",
       "3       United Kingdom        NaN  English  Positive   \n",
       "4       United Kingdom        NaN  English   Neutral   \n",
       "...                ...        ...      ...       ...   \n",
       "147626  United Kingdom        NaN  English   Neutral   \n",
       "147627   United States        NaN  English   Neutral   \n",
       "147628         Unknown        NaN  English  Negative   \n",
       "147629  United Kingdom        NaN  English  Negative   \n",
       "147630         Unknown        NaN  English  Positive   \n",
       "\n",
       "                                              Key Phrases  \\\n",
       "0                                                     NaN   \n",
       "1                                   hell bent,precious EU   \n",
       "2                          Johnson leadership,Tory voters   \n",
       "3                                               best city   \n",
       "4                    credible Brexiteer,droves,likelihood   \n",
       "...                                                   ...   \n",
       "147626     Tory party,main man,rough ride,undemocratic EU   \n",
       "147627  country,famous recent example,fight for freedo...   \n",
       "147628                                                NaN   \n",
       "147629  freedom,passionate defence,support,vaccine tas...   \n",
       "147630  advances,bitter unhealthy obsession,great spee...   \n",
       "\n",
       "                    Keywords Alternate Date Format      Time  \\\n",
       "0                     Brexit          Jan 15, 2022  11:58 PM   \n",
       "1                         EU          Jan 15, 2022  11:57 PM   \n",
       "2                  Brexit,EU          Jan 15, 2022  11:56 PM   \n",
       "3                     Brexit          Jan 15, 2022  11:54 PM   \n",
       "4       Brexiteers,Brexiteer          Jan 15, 2022  11:53 PM   \n",
       "...                      ...                   ...       ...   \n",
       "147626                    EU          Mar 20, 2022  12:01 AM   \n",
       "147627             Brexit,EU          Mar 20, 2022  12:00 AM   \n",
       "147628              European          Mar 20, 2022  12:00 AM   \n",
       "147629                Brexit          Mar 20, 2022  12:00 AM   \n",
       "147630                Brexit          Mar 20, 2022  12:00 AM   \n",
       "\n",
       "                   State       City  \n",
       "0                  North        NaN  \n",
       "1                England        NaN  \n",
       "2       Northern Ireland    Belfast  \n",
       "3                    NaN        NaN  \n",
       "4                England        NaN  \n",
       "...                  ...        ...  \n",
       "147626           England  Lichfield  \n",
       "147627      Pennsylvania    Bristol  \n",
       "147628               NaN        NaN  \n",
       "147629           England     London  \n",
       "147630               NaN        NaN  \n",
       "\n",
       "[147631 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brexitdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a597d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaun\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Key Phrases</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Alternate Date Format</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Classification_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15-Jan-2022 11:58PM</td>\n",
       "      <td>qt value brexit ; tory mp back constituency we...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:58 PM</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-Jan-2022 11:57PM</td>\n",
       "      <td>michael fabricant absolutely right dangerous e...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>hell bent,precious EU</td>\n",
       "      <td>EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:57 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Jan-2022 11:56PM</td>\n",
       "      <td>find rich ; tory voter assume unionists/conser...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson leadership,Tory voters</td>\n",
       "      <td>Brexit,EU</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:56 PM</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Jan-2022 11:54PM</td>\n",
       "      <td>brexit britain win london named best city youn...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Positive</td>\n",
       "      <td>best city</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:54 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-Jan-2022 11:53PM</td>\n",
       "      <td>johnson taken tory likelihood imposed pm remai...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>credible Brexiteer,droves,likelihood</td>\n",
       "      <td>Brexiteers,Brexiteer</td>\n",
       "      <td>Jan 15, 2022</td>\n",
       "      <td>11:53 PM</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                               Text  \\\n",
       "0  15-Jan-2022 11:58PM  qt value brexit ; tory mp back constituency we...   \n",
       "1  15-Jan-2022 11:57PM  michael fabricant absolutely right dangerous e...   \n",
       "2  15-Jan-2022 11:56PM  find rich ; tory voter assume unionists/conser...   \n",
       "3  15-Jan-2022 11:54PM  brexit britain win london named best city youn...   \n",
       "4  15-Jan-2022 11:53PM  johnson taken tory likelihood imposed pm remai...   \n",
       "\n",
       "    Source         Country  Subregion Language Sentiment  \\\n",
       "0  Twitter        Cameroon        NaN  English   Neutral   \n",
       "1  Twitter  United Kingdom        NaN  English  Negative   \n",
       "2  Twitter  United Kingdom        NaN  English  Negative   \n",
       "3  Twitter  United Kingdom        NaN  English  Positive   \n",
       "4  Twitter  United Kingdom        NaN  English   Neutral   \n",
       "\n",
       "                            Key Phrases              Keywords  \\\n",
       "0                                   NaN                Brexit   \n",
       "1                 hell bent,precious EU                    EU   \n",
       "2        Johnson leadership,Tory voters             Brexit,EU   \n",
       "3                             best city                Brexit   \n",
       "4  credible Brexiteer,droves,likelihood  Brexiteers,Brexiteer   \n",
       "\n",
       "  Alternate Date Format      Time             State     City  Classification  \\\n",
       "0          Jan 15, 2022  11:58 PM             North      NaN               0   \n",
       "1          Jan 15, 2022  11:57 PM           England      NaN               0   \n",
       "2          Jan 15, 2022  11:56 PM  Northern Ireland  Belfast               0   \n",
       "3          Jan 15, 2022  11:54 PM               NaN      NaN               0   \n",
       "4          Jan 15, 2022  11:53 PM           England      NaN               0   \n",
       "\n",
       "  Classification_Label  \n",
       "0              Neither  \n",
       "1              Neither  \n",
       "2              Neither  \n",
       "3              Neither  \n",
       "4              Neither  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Define the path where the model and tokenizer were saved\n",
    "model_save_path = 'ctoraman/hate-speech-bert'\n",
    "\n",
    "# Load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained(model_save_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Function to classify a single tweet\n",
    "def classify_tweet(tweet):\n",
    "    # Tokenize the tweet and convert to tensor\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Get model output (logits)\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted class (e.g., 2, 1, 0 for 'Hate', 'Offensive', 'Neither')\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Apply the classify_tweet function to each row of the 'Tweet' column and create a new column 'Classification'\n",
    "Brexitdf['Classification'] = Brexitdf['Text'].apply(classify_tweet)\n",
    "\n",
    "# Map class IDs to labels \n",
    "class_mapping = {2: 'Hate', 1: 'Offensive', 0: 'Neither'}\n",
    "Brexitdf['Classification_Label'] = Brexitdf['Classification'].map(class_mapping)\n",
    "\n",
    "# Print the DataFrame with new columns\n",
    "Brexitdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74278cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brexitdf.to_csv('Brexit_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcfd719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neither      134599\n",
       "Offensive     12637\n",
       "Hate            395\n",
       "Name: Classification_Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brexitdf['Classification_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e597bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neither      134599\n",
       "Offensive     12637\n",
       "Hate            395\n",
       "Name: Classification_Label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brexitdf['Classification_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53abf80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jan 15, 2022', 'Jan 14, 2022', 'Jan 13, 2022', 'Jan 12, 2022',\n",
       "       'Jan 11, 2022', 'Jan 10, 2022', 'Jan 9, 2022', 'Jan 8, 2022',\n",
       "       'Jan 7, 2022', 'Jan 6, 2022', 'Jan 5, 2022', 'Jan 4, 2022',\n",
       "       'Jan 3, 2022', 'Jan 2, 2022', 'Jan 1, 2022', 'Jan 26, 2022',\n",
       "       'Jan 25, 2022', 'Jan 24, 2022', 'Jan 23, 2022', 'Jan 22, 2022',\n",
       "       'Jan 21, 2022', 'Jan 20, 2022', 'Jan 19, 2022', 'Jan 18, 2022',\n",
       "       'Jan 17, 2022', 'Jan 16, 2022', 'Feb 7, 2022', 'Feb 6, 2022',\n",
       "       'Feb 5, 2022', 'Feb 4, 2022', 'Feb 3, 2022', 'Feb 2, 2022',\n",
       "       'Feb 1, 2022', 'Jan 31, 2022', 'Jan 30, 2022', 'Jan 29, 2022',\n",
       "       'Jan 28, 2022', 'Jan 27, 2022', 'Feb 18, 2022', 'Feb 17, 2022',\n",
       "       'Feb 16, 2022', 'Feb 15, 2022', 'Feb 14, 2022', 'Feb 13, 2022',\n",
       "       'Feb 12, 2022', 'Feb 11, 2022', 'Feb 10, 2022', 'Feb 9, 2022',\n",
       "       'Feb 8, 2022', 'Feb 27, 2022', 'Feb 26, 2022', 'Feb 25, 2022',\n",
       "       'Feb 24, 2022', 'Feb 23, 2022', 'Feb 22, 2022', 'Feb 21, 2022',\n",
       "       'Feb 20, 2022', 'Feb 19, 2022', 'Mar 8, 2022', 'Mar 7, 2022',\n",
       "       'Mar 6, 2022', 'Mar 5, 2022', 'Mar 4, 2022', 'Mar 3, 2022',\n",
       "       'Mar 2, 2022', 'Mar 1, 2022', 'Feb 28, 2022', 'Mar 19, 2022',\n",
       "       'Mar 18, 2022', 'Mar 17, 2022', 'Mar 16, 2022', 'Mar 15, 2022',\n",
       "       'Mar 14, 2022', 'Mar 13, 2022', 'Mar 12, 2022', 'Mar 11, 2022',\n",
       "       'Mar 10, 2022', 'Mar 9, 2022', 'Mar 31, 2022', 'Mar 30, 2022',\n",
       "       'Mar 29, 2022', 'Mar 28, 2022', 'Mar 27, 2022', 'Mar 26, 2022',\n",
       "       'Mar 25, 2022', 'Mar 24, 2022', 'Mar 23, 2022', 'Mar 22, 2022',\n",
       "       'Mar 21, 2022', 'Mar 20, 2022'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Brexitdf['Alternate Date Format'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eae8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
